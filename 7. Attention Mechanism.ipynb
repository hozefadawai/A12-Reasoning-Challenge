{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffmYBSOtUOYP"
      },
      "source": [
        "# Attention Mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This below entire code has been taken from this following github [link](https://github.com/SebiSebi/AI2-Reasoning-Challenge-ARC/tree/master/AttentiveRanker/src) which is the main author of the research paper.\n",
        "I have done some modification to the code as per the requirement."
      ],
      "metadata": {
        "id": "ewEa9oxCUOYU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c20acc5-1e42-4c5f-8bc2-9b9871691ab6",
        "id": "IgUECKGbUOYX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1R3DurgEQ4GZxByej_z7eRmSmONzUOHiE\n",
            "To: /content/arc_dataset_challnege_final_scores.pkl\n",
            "100% 53.5M/53.5M [00:00<00:00, 127MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1p153SuoNB9rIEKCMdKC4y2UONnvb8dyQ\n",
            "From (redirected): https://drive.google.com/uc?id=1p153SuoNB9rIEKCMdKC4y2UONnvb8dyQ&confirm=t&uuid=e65e2f03-35e5-47c8-b025-e89e60da36d0\n",
            "To: /content/arc_dataset_easy_final_scores.pkl\n",
            "100% 106M/106M [00:02<00:00, 40.7MB/s] \n"
          ]
        }
      ],
      "source": [
        "# downloading dataset direct from Gdrive with DRD and AVD scores\n",
        "!gdown 1R3DurgEQ4GZxByej_z7eRmSmONzUOHiE\n",
        "!gdown 1p153SuoNB9rIEKCMdKC4y2UONnvb8dyQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAxy68cGUOYc"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "train_challenge, dev_challenge, test_challenge= \\\n",
        "pickle.load(open('arc_dataset_challnege_final_scores.pkl', 'rb'))\n",
        "\n",
        "train_easy, dev_easy, test_easy= \\\n",
        "pickle.load(open('arc_dataset_easy_final_scores.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P_Q2ApmUOYk"
      },
      "source": [
        "### Key Value Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRG9UD8EUOYo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "from keras import backend as K\n",
        "# from tensorflow.keras.engine import Layer\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "# This attention is similar to the Key-Value-Query self-attention but\n",
        "# only uses the Key and the Value since we don't need the third component\n",
        "# for this use case. The main application of the KV attention is to\n",
        "# select the most important timestamps from a time-series using self\n",
        "# information: that is, there is no other tensor to compute attention to.\n",
        "# KV attention works as follow:\n",
        "#  * Let x be the input with shape (batch_size, timestamps, size).\n",
        "#  * Let xt be the component of x at timestamp t (shape = (size,))\n",
        "#  * Each xt is projected onto the key vector space and onto the\n",
        "#    value vector space using independent matrices.\n",
        "#  * Furthermore, each element from the key space is projected\n",
        "#    into a single scalar using a dot product. These values are then\n",
        "#    normalized using the softmax function;\n",
        "#  * The vectors in the Value space are summed according to the probabilities\n",
        "#    and the weighted sum is the final output of the layer.\n",
        "# A quick draw with the graph can be found:\n",
        "#  * here: http://bit.do/eL7kf and\n",
        "#  * here: https://tinyurl.com/y5ncha3b (same image).\n",
        "# key_size = the dimention of the key vector space.\n",
        "# value_size = the dimention of the value vector space.\n",
        "# Both are required.\n",
        "class KVAttention(Layer):\n",
        "\n",
        "    # attention_size is the variable @k from the paper.\n",
        "    def __init__(self, key_size, value_size,\n",
        "                 return_attention_scores=False, **kwargs):\n",
        "        if K.backend() != 'tensorflow':\n",
        "            raise RuntimeError('KVAttention is only available with '\n",
        "                               'the TensorFlow backend.')\n",
        "        assert(isinstance(key_size, int) and key_size >= 1)\n",
        "        assert(isinstance(value_size, int) and value_size >= 1)\n",
        "        assert(isinstance(return_attention_scores, bool))\n",
        "\n",
        "        self.key_size = key_size\n",
        "        self.value_size = value_size\n",
        "        self.return_attention_scores = return_attention_scores\n",
        "        self.imput_dim = None\n",
        "        self.timestamps = None\n",
        "\n",
        "        super(KVAttention, self).__init__(**kwargs)\n",
        "\n",
        "    # The model receives an input with shape (batch_size, timestamp, input_dim)\n",
        "    def build(self, input_shape):\n",
        "        assert(len(input_shape) == 3)\n",
        "\n",
        "        self.timestamps = input_shape[1]\n",
        "        self.input_dim = input_shape[2]\n",
        "\n",
        "        self.key_embed_w = self.add_weight(\n",
        "                        shape=(self.input_dim, self.key_size),\n",
        "                        name='key_embed_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_embed_b = self.add_weight(\n",
        "                        shape=(self.key_size,),\n",
        "                        name='key_embed_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_to_scalar_w = self.add_weight(\n",
        "                        shape=(self.key_size, 1),\n",
        "                        name='key_to_scalar_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.key_to_scalar_b = self.add_weight(\n",
        "                        shape=(1,),\n",
        "                        name='key_to_scalar_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.value_embed_w = self.add_weight(\n",
        "                        shape=(self.input_dim, self.value_size),\n",
        "                        name='value_embed_w',\n",
        "                        initializer='glorot_uniform',\n",
        "                        trainable=True\n",
        "        )\n",
        "        self.value_embed_b = self.add_weight(\n",
        "                        shape=(self.value_size,),\n",
        "                        name='value_embed_b',\n",
        "                        initializer='zeros',\n",
        "                        trainable=True\n",
        "        )\n",
        "\n",
        "        super(KVAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        input_tensor = inputs  # (batch_size, timestamp, input_dim)\n",
        "        assert(len(input_tensor.shape) == 3)\n",
        "        assert(input_tensor.shape[1] == self.timestamps)\n",
        "        assert(input_tensor.shape[2] == self.input_dim)\n",
        "\n",
        "        # K = tanh(W_emb * input_tensor + b_emb).\n",
        "        K = tf.reshape(input_tensor, [-1, self.input_dim])\n",
        "        K = tf.compat.v1.nn.xw_plus_b(K, self.key_embed_w, self.key_embed_b)\n",
        "        K = tf.tanh(K)  # K.shape = (batch * timestamp, key_size)\n",
        "\n",
        "        # Further encode the key into a single scalar for each timestamp.\n",
        "        K = tf.compat.v1.nn.xw_plus_b(K, self.key_to_scalar_w, self.key_to_scalar_b)\n",
        "        K = tf.tanh(K)  # K.shape = (batch * timestamp, 1)\n",
        "        K = tf.reshape(K, [-1, self.timestamps])\n",
        "        # K.shape = (batch_size, timestamp)\n",
        "\n",
        "        # Apply softmax to the Key tensor.\n",
        "        assert(len(K.shape) == 2)\n",
        "        assert(K.shape[1] == self.timestamps)\n",
        "        P = tf.nn.softmax(K)  # P.shape (batch_size, timestamps)\n",
        "        assert(P.shape[1:] == K.shape[1:])\n",
        "        if self.return_attention_scores:\n",
        "            return P\n",
        "\n",
        "        # Build the Value vector (key part is completed, we have P).\n",
        "        # V = tanh(W_emb2 * input_tensor + b_emb2).\n",
        "        V = tf.reshape(input_tensor, [-1, self.input_dim])\n",
        "        V = tf.compat.v1.nn.xw_plus_b(V, self.value_embed_w, self.value_embed_b)\n",
        "        V = tf.nn.relu(V)  # V.shape = (batch * timestamp, value_size)\n",
        "        V = tf.reshape(V, [-1, self.timestamps, self.value_size])\n",
        "        # V.shape = (batch_size, timestamp, value_size)\n",
        "\n",
        "        # Perform the weighted sum.\n",
        "        P = tf.expand_dims(P, 1)\n",
        "        # P.shape = (batch_size, 1, timestamps)\n",
        "        # V.shape = (batch_size, timestamps, value_size)\n",
        "\n",
        "        out = tf.matmul(P, V)\n",
        "        assert(len(out.shape) == 3)\n",
        "        assert(out.shape[1] == 1)\n",
        "        out = tf.squeeze(out, axis=1)\n",
        "        assert(out.shape[1] == self.value_size)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        assert(isinstance(input_shape, tuple))\n",
        "        assert(len(input_shape) == 3)\n",
        "        if self.return_attention_scores:\n",
        "            return (input_shape[0], self.timestamps)\n",
        "        return (input_shape[0], self.value_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPCIAdirUOYt"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ_v-Sd9UOYv"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import json\n",
        "import numpy as np\n",
        "import uuid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Returns a list of entries. To be fed into @to_numpy to extract tensors\n",
        "# that can be directly wired to Keras @fit.\n",
        "# Augment the dataset with all answer permutations such that the neural\n",
        "# network cannot learn how to decide based on positions.\n",
        "# Returns the newly constructed dataset.\n",
        "def augment_with_permutations(dataset):\n",
        "    #assert(isinstance(dataset, list))\n",
        "    augmented = []\n",
        "\n",
        "    ans ={\n",
        "      'A': 0,\n",
        "      'B': 1,\n",
        "      'C': 2,\n",
        "      'D': 3,\n",
        "      '1': 0,\n",
        "      '2': 1,\n",
        "      '3': 2,\n",
        "      '4': 3}\n",
        "\n",
        "    for idx, entry in dataset.iterrows():\n",
        "\n",
        "      if len(entry[\"score\"]) == 5: continue\n",
        "\n",
        "      lst = [item for sublist in entry['score'] for item in sublist]\n",
        "\n",
        "      if len(lst) == 200:\n",
        "\n",
        "        answers = entry[\"score\"]\n",
        "        correct_answer = ans[entry[\"AnswerKey\"]]\n",
        "\n",
        "        # correct_answer = entry[\"correct_answer\"]\n",
        "        # answers = entry[\"answers\"]\n",
        "        documents = entry[\"context\"]\n",
        "        answers_text = entry[\"only_answers\"]\n",
        "\n",
        "        for perm in itertools.permutations([0, 1, 2, 3]):\n",
        "            permuted_answers = [answers[i] for i in perm]\n",
        "            permuted_answers_text = [answers_text[i] for i in perm]\n",
        "            permuted_documents = [documents[i] for i in perm]\n",
        "            permuted_correct_answer = perm.index(correct_answer)\n",
        "            assert(permuted_correct_answer in [0, 1, 2, 3])\n",
        "            augmented.append({\n",
        "                    \"AnswerKey\": permuted_correct_answer,\n",
        "                    \"score\": permuted_answers,\n",
        "                    \"only_questions\": entry[\"only_questions\"],\n",
        "                    \"context\": permuted_documents,\n",
        "                    \"only_answers\": permuted_answers_text\n",
        "            })\n",
        "\n",
        "    return augmented\n",
        "\n",
        "\n",
        "# Returns a dictionary of entries (for answers) and their labels. To be\n",
        "# directly wired into Keras methods (fit, predict, etc.).\n",
        "# Does not shuffle the questions.\n",
        "def my_numpy(dataset, NUM_FEATURES):\n",
        "\n",
        "    NUM_SOURCES= 2\n",
        "    top_n = 25\n",
        "    answer_a = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_b = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_c = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    answer_d = np.zeros((len(dataset), NUM_SOURCES * top_n, NUM_FEATURES),\n",
        "                        dtype=\"float\")\n",
        "    labels = np.zeros((len(dataset), 4), dtype=\"int32\")\n",
        "\n",
        "    ans ={\n",
        "      'A': 0,\n",
        "      'B': 1,\n",
        "      'C': 2,\n",
        "      'D': 3,\n",
        "       0: 0,\n",
        "       1: 1,\n",
        "       2: 2,\n",
        "       3: 3}\n",
        "\n",
        "    for (idx, entry) in enumerate(dataset):\n",
        "\n",
        "      if len(entry[\"score\"]) == 5: continue\n",
        "\n",
        "      lst = [item for sublist in entry['score'] for item in sublist]\n",
        "\n",
        "      if len(lst) == 200:\n",
        "\n",
        "        answers = entry[\"score\"]\n",
        "        correct_answer = entry[\"AnswerKey\"]\n",
        "\n",
        "        # this code snippet will take score with answer verifier\n",
        "        if NUM_FEATURES == 3:\n",
        "          answer_a[idx] = np.array(answers[0], dtype=\"float\")\n",
        "          answer_b[idx] = np.array(answers[1], dtype=\"float\")\n",
        "          answer_c[idx] = np.array(answers[2], dtype=\"float\")\n",
        "          answer_d[idx] = np.array(answers[3], dtype=\"float\")\n",
        "          # print(correct_answer)\n",
        "          labels[idx][ans[correct_answer]] = 1\n",
        "\n",
        "        # this code snippet will take score without answer verifier\n",
        "        if NUM_FEATURES == 2:\n",
        "          # print((answers[0]))\n",
        "          answer_a[idx] = np.array([i[:2] for i in answers[0]], dtype=\"float\").reshape(50,2)\n",
        "          answer_b[idx] = np.array([i[:2] for i in answers[1]], dtype=\"float\").reshape(50,2)\n",
        "          answer_c[idx] = np.array([i[:2] for i in answers[2]], dtype=\"float\").reshape(50,2)\n",
        "          answer_d[idx] = np.array([i[:2] for i in answers[3]], dtype=\"float\").reshape(50,2)\n",
        "          # print(correct_answer)\n",
        "          labels[idx][ans[correct_answer]] = 1\n",
        "\n",
        "    return {\n",
        "            \"answer_a\": answer_a,\n",
        "            \"answer_b\": answer_b,\n",
        "            \"answer_c\": answer_c,\n",
        "            \"answer_d\": answer_d\n",
        "    }, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtwXRswVUOY0"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCQLbErlUOY3"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Input, TimeDistributed, Reshape\n",
        "from keras.layers import Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "def get_model(N_points, NUM_FEATURES, return_attention_scores=False):\n",
        "\n",
        "    answer_a = Input(shape=(N_points, NUM_FEATURES), name=\"answer_a\")\n",
        "    answer_b = Input(shape=(N_points, NUM_FEATURES), name=\"answer_b\")\n",
        "    answer_c = Input(shape=(N_points, NUM_FEATURES), name=\"answer_c\")\n",
        "    answer_d = Input(shape=(N_points, NUM_FEATURES), name=\"answer_d\")\n",
        "\n",
        "\n",
        "    # These layers are shared for each answer.\n",
        "    encoder_layer1 = TimeDistributed(\n",
        "                        Dense(32, activation='tanh', name=\"dense_1\"),\n",
        "                        name=\"time_distributed_1\"\n",
        "    )\n",
        "    dropout_layer1 = SpatialDropout1D(0.25, name=\"spatial_dropout_1\")\n",
        "    to_scalar_layer = KVAttention(\n",
        "                        key_size=64, value_size=8, name=\"att\",\n",
        "                        return_attention_scores=return_attention_scores\n",
        "    )\n",
        "\n",
        "    def encode_answer(answer):\n",
        "        x = encoder_layer1(answer)\n",
        "        x = dropout_layer1(x)\n",
        "        x = to_scalar_layer(x)\n",
        "        return x\n",
        "\n",
        "    a = encode_answer(answer_a)\n",
        "    b = encode_answer(answer_b)\n",
        "    c = encode_answer(answer_c)\n",
        "    d = encode_answer(answer_d)\n",
        "\n",
        "    output = None\n",
        "    y = Concatenate(axis=-1, name=\"concatenate_1\")([a, b, c, d])\n",
        "    if return_attention_scores:\n",
        "        output = y\n",
        "    else:\n",
        "        y = Dense(32, activation='relu', name=\"dense_2\")(y)\n",
        "        y = Dropout(0.1, name=\"dropout_1\")(y)\n",
        "        y = Dense(32, activation='relu', name=\"dense_3\")(y)\n",
        "        y = Dropout(0.1, name=\"dropout_2\")(y)\n",
        "        y = Dense(32, activation='relu', name=\"dense_4\")(y)\n",
        "        output = Dense(4, activation='softmax', name=\"dense_5\")(y)\n",
        "\n",
        "    model = Model(inputs=[answer_a, answer_b, answer_c, answer_d],\n",
        "                  outputs=[output])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5pUJpXnUOY6"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy6IHm3fUOY8"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "\n",
        "def answer_with_attention_score(train, val, verifier):\n",
        "\n",
        "  '''\n",
        "  Function to get accuracy score with key value attention\n",
        "  '''\n",
        "\n",
        "  train_dataset = augment_with_permutations(train)\n",
        "  train_data, train_labels = my_numpy(train_dataset, verifier)\n",
        "\n",
        "  val_dataset = augment_with_permutations(val)\n",
        "  val_data, val_labels = my_numpy(val_dataset, verifier)\n",
        "\n",
        "\n",
        "  model = get_model(50, verifier)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer = tf.keras.optimizers.AdamW(),\n",
        "                metrics=['acc'])\n",
        "\n",
        "  model.fit(\n",
        "          train_data, train_labels,\n",
        "          validation_data=(val_data, val_labels),\n",
        "          batch_size=128,\n",
        "          epochs=256,\n",
        "          verbose=1,\n",
        "  )\n",
        "\n",
        "  data, labels= train_data, train_labels\n",
        "\n",
        "  y = model.predict(data, batch_size=1024)\n",
        "  assert(y.shape == (labels.shape[0], 4))\n",
        "\n",
        "  num_questions = labels.shape[0]\n",
        "  correct = 0\n",
        "  for i in range(0, num_questions):\n",
        "      expected = np.argmax(labels[i])\n",
        "      predicted = np.argmax(y[i])\n",
        "      if expected == predicted:\n",
        "          correct += 1\n",
        "  return (100.0 * correct / num_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6984c1-268c-44ed-ef5e-245bdc79dc62",
        "id": "H3UW26EdUOZA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 243ms/step - acc: 0.2489 - loss: 1.3882 - val_acc: 0.2498 - val_loss: 1.3863\n",
            "Epoch 2/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - acc: 0.2520 - loss: 1.3864 - val_acc: 0.2475 - val_loss: 1.3863\n",
            "Epoch 3/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2537 - loss: 1.3863 - val_acc: 0.2500 - val_loss: 1.3862\n",
            "Epoch 4/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2536 - loss: 1.3861 - val_acc: 0.2754 - val_loss: 1.3858\n",
            "Epoch 5/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2569 - loss: 1.3858 - val_acc: 0.2646 - val_loss: 1.3851\n",
            "Epoch 6/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2730 - loss: 1.3846 - val_acc: 0.2980 - val_loss: 1.3812\n",
            "Epoch 7/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2790 - loss: 1.3824 - val_acc: 0.2891 - val_loss: 1.3797\n",
            "Epoch 8/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.2767 - loss: 1.3806 - val_acc: 0.3146 - val_loss: 1.3757\n",
            "Epoch 9/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.2817 - loss: 1.3802 - val_acc: 0.2949 - val_loss: 1.3760\n",
            "Epoch 10/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.2846 - loss: 1.3773 - val_acc: 0.3004 - val_loss: 1.3755\n",
            "Epoch 11/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2871 - loss: 1.3774 - val_acc: 0.3014 - val_loss: 1.3755\n",
            "Epoch 12/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2877 - loss: 1.3769 - val_acc: 0.3077 - val_loss: 1.3747\n",
            "Epoch 13/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2868 - loss: 1.3758 - val_acc: 0.3046 - val_loss: 1.3733\n",
            "Epoch 14/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.2905 - loss: 1.3753 - val_acc: 0.2986 - val_loss: 1.3749\n",
            "Epoch 15/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2874 - loss: 1.3739 - val_acc: 0.2923 - val_loss: 1.3768\n",
            "Epoch 16/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2901 - loss: 1.3746 - val_acc: 0.3000 - val_loss: 1.3727\n",
            "Epoch 17/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2937 - loss: 1.3735 - val_acc: 0.2960 - val_loss: 1.3745\n",
            "Epoch 18/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3019 - loss: 1.3711 - val_acc: 0.2998 - val_loss: 1.3760\n",
            "Epoch 19/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3035 - loss: 1.3696 - val_acc: 0.3047 - val_loss: 1.3715\n",
            "Epoch 20/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3099 - loss: 1.3703 - val_acc: 0.3115 - val_loss: 1.3715\n",
            "Epoch 21/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3068 - loss: 1.3680 - val_acc: 0.3043 - val_loss: 1.3702\n",
            "Epoch 22/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3084 - loss: 1.3701 - val_acc: 0.3087 - val_loss: 1.3697\n",
            "Epoch 23/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3083 - loss: 1.3685 - val_acc: 0.2981 - val_loss: 1.3683\n",
            "Epoch 24/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3151 - loss: 1.3643 - val_acc: 0.3144 - val_loss: 1.3639\n",
            "Epoch 25/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3166 - loss: 1.3637 - val_acc: 0.3255 - val_loss: 1.3603\n",
            "Epoch 26/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3143 - loss: 1.3634 - val_acc: 0.3238 - val_loss: 1.3588\n",
            "Epoch 27/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3194 - loss: 1.3624 - val_acc: 0.3349 - val_loss: 1.3567\n",
            "Epoch 28/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3150 - loss: 1.3611 - val_acc: 0.3384 - val_loss: 1.3547\n",
            "Epoch 29/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3165 - loss: 1.3601 - val_acc: 0.3421 - val_loss: 1.3535\n",
            "Epoch 30/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3180 - loss: 1.3603 - val_acc: 0.3384 - val_loss: 1.3534\n",
            "Epoch 31/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3222 - loss: 1.3553 - val_acc: 0.3430 - val_loss: 1.3531\n",
            "Epoch 32/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3159 - loss: 1.3586 - val_acc: 0.3406 - val_loss: 1.3534\n",
            "Epoch 33/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3198 - loss: 1.3590 - val_acc: 0.3421 - val_loss: 1.3528\n",
            "Epoch 34/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3289 - loss: 1.3541 - val_acc: 0.3426 - val_loss: 1.3539\n",
            "Epoch 35/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3230 - loss: 1.3524 - val_acc: 0.3487 - val_loss: 1.3522\n",
            "Epoch 36/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3220 - loss: 1.3527 - val_acc: 0.3561 - val_loss: 1.3492\n",
            "Epoch 37/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3107 - loss: 1.3564 - val_acc: 0.3410 - val_loss: 1.3550\n",
            "Epoch 38/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3268 - loss: 1.3508 - val_acc: 0.3406 - val_loss: 1.3533\n",
            "Epoch 39/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3260 - loss: 1.3514 - val_acc: 0.3573 - val_loss: 1.3489\n",
            "Epoch 40/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3216 - loss: 1.3533 - val_acc: 0.3570 - val_loss: 1.3486\n",
            "Epoch 41/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3311 - loss: 1.3470 - val_acc: 0.3478 - val_loss: 1.3462\n",
            "Epoch 42/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3266 - loss: 1.3474 - val_acc: 0.3539 - val_loss: 1.3473\n",
            "Epoch 43/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3304 - loss: 1.3469 - val_acc: 0.3444 - val_loss: 1.3447\n",
            "Epoch 44/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3308 - loss: 1.3462 - val_acc: 0.3426 - val_loss: 1.3462\n",
            "Epoch 45/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3273 - loss: 1.3460 - val_acc: 0.3487 - val_loss: 1.3510\n",
            "Epoch 46/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3254 - loss: 1.3458 - val_acc: 0.3438 - val_loss: 1.3488\n",
            "Epoch 47/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3288 - loss: 1.3433 - val_acc: 0.3421 - val_loss: 1.3516\n",
            "Epoch 48/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - acc: 0.3240 - loss: 1.3437 - val_acc: 0.3419 - val_loss: 1.3541\n",
            "Epoch 49/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - acc: 0.3278 - loss: 1.3441 - val_acc: 0.3410 - val_loss: 1.3560\n",
            "Epoch 50/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3262 - loss: 1.3424 - val_acc: 0.3378 - val_loss: 1.3524\n",
            "Epoch 51/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3322 - loss: 1.3414 - val_acc: 0.3306 - val_loss: 1.3533\n",
            "Epoch 52/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3218 - loss: 1.3422 - val_acc: 0.3575 - val_loss: 1.3504\n",
            "Epoch 53/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - acc: 0.3331 - loss: 1.3373 - val_acc: 0.3476 - val_loss: 1.3531\n",
            "Epoch 54/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - acc: 0.3349 - loss: 1.3373 - val_acc: 0.3441 - val_loss: 1.3541\n",
            "Epoch 55/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - acc: 0.3286 - loss: 1.3403 - val_acc: 0.3346 - val_loss: 1.3528\n",
            "Epoch 56/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - acc: 0.3292 - loss: 1.3388 - val_acc: 0.3366 - val_loss: 1.3561\n",
            "Epoch 57/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3280 - loss: 1.3346 - val_acc: 0.3395 - val_loss: 1.3529\n",
            "Epoch 58/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3337 - loss: 1.3362 - val_acc: 0.3349 - val_loss: 1.3584\n",
            "Epoch 59/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3339 - loss: 1.3331 - val_acc: 0.3399 - val_loss: 1.3582\n",
            "Epoch 60/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3342 - loss: 1.3348 - val_acc: 0.3395 - val_loss: 1.3575\n",
            "Epoch 61/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3290 - loss: 1.3351 - val_acc: 0.3358 - val_loss: 1.3551\n",
            "Epoch 62/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3315 - loss: 1.3315 - val_acc: 0.3275 - val_loss: 1.3593\n",
            "Epoch 63/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3297 - loss: 1.3345 - val_acc: 0.3367 - val_loss: 1.3570\n",
            "Epoch 64/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3321 - loss: 1.3339 - val_acc: 0.3329 - val_loss: 1.3590\n",
            "Epoch 65/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3301 - loss: 1.3316 - val_acc: 0.3418 - val_loss: 1.3595\n",
            "Epoch 66/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3273 - loss: 1.3348 - val_acc: 0.3378 - val_loss: 1.3660\n",
            "Epoch 67/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3270 - loss: 1.3327 - val_acc: 0.3356 - val_loss: 1.3574\n",
            "Epoch 68/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3367 - loss: 1.3258 - val_acc: 0.3390 - val_loss: 1.3612\n",
            "Epoch 69/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3372 - loss: 1.3269 - val_acc: 0.3319 - val_loss: 1.3574\n",
            "Epoch 70/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3333 - loss: 1.3276 - val_acc: 0.3304 - val_loss: 1.3563\n",
            "Epoch 71/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3315 - loss: 1.3278 - val_acc: 0.3393 - val_loss: 1.3597\n",
            "Epoch 72/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3348 - loss: 1.3263 - val_acc: 0.3403 - val_loss: 1.3592\n",
            "Epoch 73/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3335 - loss: 1.3307 - val_acc: 0.3396 - val_loss: 1.3597\n",
            "Epoch 74/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3297 - loss: 1.3298 - val_acc: 0.3313 - val_loss: 1.3638\n",
            "Epoch 75/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3384 - loss: 1.3224 - val_acc: 0.3287 - val_loss: 1.3593\n",
            "Epoch 76/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3344 - loss: 1.3262 - val_acc: 0.3313 - val_loss: 1.3661\n",
            "Epoch 77/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3341 - loss: 1.3218 - val_acc: 0.3356 - val_loss: 1.3648\n",
            "Epoch 78/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3388 - loss: 1.3226 - val_acc: 0.3329 - val_loss: 1.3652\n",
            "Epoch 79/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3298 - loss: 1.3253 - val_acc: 0.3301 - val_loss: 1.3613\n",
            "Epoch 80/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3375 - loss: 1.3274 - val_acc: 0.3292 - val_loss: 1.3633\n",
            "Epoch 81/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3302 - loss: 1.3291 - val_acc: 0.3284 - val_loss: 1.3636\n",
            "Epoch 82/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3387 - loss: 1.3190 - val_acc: 0.3260 - val_loss: 1.3648\n",
            "Epoch 83/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3352 - loss: 1.3233 - val_acc: 0.3247 - val_loss: 1.3684\n",
            "Epoch 84/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3377 - loss: 1.3230 - val_acc: 0.3329 - val_loss: 1.3642\n",
            "Epoch 85/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3360 - loss: 1.3242 - val_acc: 0.3338 - val_loss: 1.3658\n",
            "Epoch 86/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3346 - loss: 1.3223 - val_acc: 0.3329 - val_loss: 1.3692\n",
            "Epoch 87/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3364 - loss: 1.3209 - val_acc: 0.3293 - val_loss: 1.3644\n",
            "Epoch 88/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3362 - loss: 1.3187 - val_acc: 0.3384 - val_loss: 1.3646\n",
            "Epoch 89/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3405 - loss: 1.3187 - val_acc: 0.3316 - val_loss: 1.3662\n",
            "Epoch 90/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3370 - loss: 1.3199 - val_acc: 0.3339 - val_loss: 1.3640\n",
            "Epoch 91/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3426 - loss: 1.3190 - val_acc: 0.3339 - val_loss: 1.3702\n",
            "Epoch 92/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3376 - loss: 1.3218 - val_acc: 0.3396 - val_loss: 1.3691\n",
            "Epoch 93/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3415 - loss: 1.3185 - val_acc: 0.3255 - val_loss: 1.3665\n",
            "Epoch 94/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3435 - loss: 1.3200 - val_acc: 0.3433 - val_loss: 1.3681\n",
            "Epoch 95/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3371 - loss: 1.3200 - val_acc: 0.3304 - val_loss: 1.3635\n",
            "Epoch 96/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3396 - loss: 1.3156 - val_acc: 0.3293 - val_loss: 1.3677\n",
            "Epoch 97/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3473 - loss: 1.3113 - val_acc: 0.3384 - val_loss: 1.3669\n",
            "Epoch 98/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3332 - loss: 1.3160 - val_acc: 0.3399 - val_loss: 1.3649\n",
            "Epoch 99/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3420 - loss: 1.3143 - val_acc: 0.3355 - val_loss: 1.3705\n",
            "Epoch 100/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3452 - loss: 1.3146 - val_acc: 0.3272 - val_loss: 1.3657\n",
            "Epoch 101/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3458 - loss: 1.3138 - val_acc: 0.3316 - val_loss: 1.3749\n",
            "Epoch 102/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3442 - loss: 1.3162 - val_acc: 0.3281 - val_loss: 1.3782\n",
            "Epoch 103/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3386 - loss: 1.3139 - val_acc: 0.3296 - val_loss: 1.3695\n",
            "Epoch 104/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3405 - loss: 1.3128 - val_acc: 0.3250 - val_loss: 1.3689\n",
            "Epoch 105/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3429 - loss: 1.3133 - val_acc: 0.3367 - val_loss: 1.3687\n",
            "Epoch 106/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3404 - loss: 1.3145 - val_acc: 0.3341 - val_loss: 1.3634\n",
            "Epoch 107/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3395 - loss: 1.3183 - val_acc: 0.3316 - val_loss: 1.3703\n",
            "Epoch 108/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3454 - loss: 1.3088 - val_acc: 0.3232 - val_loss: 1.3716\n",
            "Epoch 109/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3439 - loss: 1.3172 - val_acc: 0.3241 - val_loss: 1.3773\n",
            "Epoch 110/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3447 - loss: 1.3123 - val_acc: 0.3287 - val_loss: 1.3720\n",
            "Epoch 111/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - acc: 0.3501 - loss: 1.3104 - val_acc: 0.3258 - val_loss: 1.3742\n",
            "Epoch 112/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3311 - loss: 1.3147 - val_acc: 0.3227 - val_loss: 1.3736\n",
            "Epoch 113/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3402 - loss: 1.3109 - val_acc: 0.3210 - val_loss: 1.3752\n",
            "Epoch 114/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3472 - loss: 1.3126 - val_acc: 0.3378 - val_loss: 1.3705\n",
            "Epoch 115/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3491 - loss: 1.3091 - val_acc: 0.3258 - val_loss: 1.3715\n",
            "Epoch 116/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3430 - loss: 1.3051 - val_acc: 0.3190 - val_loss: 1.3806\n",
            "Epoch 117/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3491 - loss: 1.3081 - val_acc: 0.3169 - val_loss: 1.3780\n",
            "Epoch 118/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3468 - loss: 1.3098 - val_acc: 0.3319 - val_loss: 1.3749\n",
            "Epoch 119/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3490 - loss: 1.3043 - val_acc: 0.3255 - val_loss: 1.3747\n",
            "Epoch 120/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3406 - loss: 1.3073 - val_acc: 0.3236 - val_loss: 1.3702\n",
            "Epoch 121/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3485 - loss: 1.3067 - val_acc: 0.3298 - val_loss: 1.3792\n",
            "Epoch 122/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3499 - loss: 1.3088 - val_acc: 0.3253 - val_loss: 1.3746\n",
            "Epoch 123/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3464 - loss: 1.3090 - val_acc: 0.3249 - val_loss: 1.3734\n",
            "Epoch 124/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3414 - loss: 1.3124 - val_acc: 0.3261 - val_loss: 1.3768\n",
            "Epoch 125/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3478 - loss: 1.3117 - val_acc: 0.3215 - val_loss: 1.3770\n",
            "Epoch 126/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3447 - loss: 1.3066 - val_acc: 0.3224 - val_loss: 1.3749\n",
            "Epoch 127/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3461 - loss: 1.3068 - val_acc: 0.3266 - val_loss: 1.3743\n",
            "Epoch 128/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3483 - loss: 1.3035 - val_acc: 0.3232 - val_loss: 1.3772\n",
            "Epoch 129/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3516 - loss: 1.3038 - val_acc: 0.3218 - val_loss: 1.3770\n",
            "Epoch 130/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3458 - loss: 1.3061 - val_acc: 0.3224 - val_loss: 1.3802\n",
            "Epoch 131/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3518 - loss: 1.2998 - val_acc: 0.3201 - val_loss: 1.3805\n",
            "Epoch 132/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3458 - loss: 1.3033 - val_acc: 0.3276 - val_loss: 1.3717\n",
            "Epoch 133/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3491 - loss: 1.3007 - val_acc: 0.3146 - val_loss: 1.3733\n",
            "Epoch 134/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3482 - loss: 1.3010 - val_acc: 0.3232 - val_loss: 1.3800\n",
            "Epoch 135/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3437 - loss: 1.3082 - val_acc: 0.3093 - val_loss: 1.3794\n",
            "Epoch 136/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3467 - loss: 1.3004 - val_acc: 0.3215 - val_loss: 1.3806\n",
            "Epoch 137/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3528 - loss: 1.2994 - val_acc: 0.3229 - val_loss: 1.3816\n",
            "Epoch 138/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3480 - loss: 1.2999 - val_acc: 0.3198 - val_loss: 1.3840\n",
            "Epoch 139/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3450 - loss: 1.3017 - val_acc: 0.3127 - val_loss: 1.3888\n",
            "Epoch 140/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3455 - loss: 1.3039 - val_acc: 0.3249 - val_loss: 1.3747\n",
            "Epoch 141/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3517 - loss: 1.2961 - val_acc: 0.3107 - val_loss: 1.3846\n",
            "Epoch 142/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3523 - loss: 1.3004 - val_acc: 0.3170 - val_loss: 1.3742\n",
            "Epoch 143/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3441 - loss: 1.3036 - val_acc: 0.3178 - val_loss: 1.3886\n",
            "Epoch 144/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3598 - loss: 1.2988 - val_acc: 0.3250 - val_loss: 1.3816\n",
            "Epoch 145/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3453 - loss: 1.3078 - val_acc: 0.3223 - val_loss: 1.3808\n",
            "Epoch 146/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3514 - loss: 1.2971 - val_acc: 0.3104 - val_loss: 1.3872\n",
            "Epoch 147/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3530 - loss: 1.2958 - val_acc: 0.3207 - val_loss: 1.3837\n",
            "Epoch 148/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3504 - loss: 1.2990 - val_acc: 0.3170 - val_loss: 1.3831\n",
            "Epoch 149/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3449 - loss: 1.3018 - val_acc: 0.3235 - val_loss: 1.3845\n",
            "Epoch 150/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3505 - loss: 1.3002 - val_acc: 0.3233 - val_loss: 1.3812\n",
            "Epoch 151/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - acc: 0.3524 - loss: 1.2926 - val_acc: 0.3146 - val_loss: 1.3826\n",
            "Epoch 152/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3495 - loss: 1.2947 - val_acc: 0.3097 - val_loss: 1.3755\n",
            "Epoch 153/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3576 - loss: 1.2922 - val_acc: 0.3218 - val_loss: 1.3844\n",
            "Epoch 154/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3472 - loss: 1.3034 - val_acc: 0.3054 - val_loss: 1.3865\n",
            "Epoch 155/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3534 - loss: 1.2952 - val_acc: 0.3126 - val_loss: 1.3877\n",
            "Epoch 156/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3494 - loss: 1.2938 - val_acc: 0.3260 - val_loss: 1.3827\n",
            "Epoch 157/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3564 - loss: 1.2952 - val_acc: 0.3040 - val_loss: 1.3892\n",
            "Epoch 158/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3557 - loss: 1.2942 - val_acc: 0.3198 - val_loss: 1.3854\n",
            "Epoch 159/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3524 - loss: 1.2969 - val_acc: 0.3227 - val_loss: 1.3819\n",
            "Epoch 160/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3494 - loss: 1.2941 - val_acc: 0.3141 - val_loss: 1.3814\n",
            "Epoch 161/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3544 - loss: 1.2929 - val_acc: 0.3227 - val_loss: 1.3856\n",
            "Epoch 162/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3593 - loss: 1.2940 - val_acc: 0.3155 - val_loss: 1.3851\n",
            "Epoch 163/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3529 - loss: 1.2975 - val_acc: 0.3081 - val_loss: 1.3842\n",
            "Epoch 164/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3606 - loss: 1.2941 - val_acc: 0.3064 - val_loss: 1.3855\n",
            "Epoch 165/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3595 - loss: 1.2930 - val_acc: 0.3103 - val_loss: 1.3848\n",
            "Epoch 166/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3529 - loss: 1.2938 - val_acc: 0.3000 - val_loss: 1.3900\n",
            "Epoch 167/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3481 - loss: 1.2932 - val_acc: 0.3132 - val_loss: 1.3897\n",
            "Epoch 168/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3604 - loss: 1.2869 - val_acc: 0.3120 - val_loss: 1.3919\n",
            "Epoch 169/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3570 - loss: 1.2908 - val_acc: 0.3035 - val_loss: 1.3917\n",
            "Epoch 170/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3563 - loss: 1.2888 - val_acc: 0.3177 - val_loss: 1.3878\n",
            "Epoch 171/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3632 - loss: 1.2860 - val_acc: 0.3026 - val_loss: 1.3887\n",
            "Epoch 172/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3523 - loss: 1.2941 - val_acc: 0.3126 - val_loss: 1.3905\n",
            "Epoch 173/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3619 - loss: 1.2876 - val_acc: 0.2966 - val_loss: 1.3834\n",
            "Epoch 174/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3489 - loss: 1.2926 - val_acc: 0.3132 - val_loss: 1.3874\n",
            "Epoch 175/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3607 - loss: 1.2875 - val_acc: 0.3133 - val_loss: 1.3915\n",
            "Epoch 176/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3513 - loss: 1.2926 - val_acc: 0.3106 - val_loss: 1.3930\n",
            "Epoch 177/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3608 - loss: 1.2862 - val_acc: 0.3147 - val_loss: 1.3964\n",
            "Epoch 178/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3632 - loss: 1.2870 - val_acc: 0.3127 - val_loss: 1.3909\n",
            "Epoch 179/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3639 - loss: 1.2880 - val_acc: 0.3195 - val_loss: 1.4028\n",
            "Epoch 180/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3629 - loss: 1.2905 - val_acc: 0.3023 - val_loss: 1.3905\n",
            "Epoch 181/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3644 - loss: 1.2879 - val_acc: 0.2960 - val_loss: 1.3895\n",
            "Epoch 182/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3589 - loss: 1.2910 - val_acc: 0.3030 - val_loss: 1.3938\n",
            "Epoch 183/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3593 - loss: 1.2858 - val_acc: 0.3084 - val_loss: 1.3887\n",
            "Epoch 184/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3564 - loss: 1.2828 - val_acc: 0.3057 - val_loss: 1.3947\n",
            "Epoch 185/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3565 - loss: 1.2851 - val_acc: 0.3038 - val_loss: 1.3979\n",
            "Epoch 186/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3655 - loss: 1.2815 - val_acc: 0.3101 - val_loss: 1.3981\n",
            "Epoch 187/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3596 - loss: 1.2839 - val_acc: 0.3080 - val_loss: 1.3919\n",
            "Epoch 188/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3658 - loss: 1.2830 - val_acc: 0.2994 - val_loss: 1.3915\n",
            "Epoch 189/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3639 - loss: 1.2856 - val_acc: 0.3175 - val_loss: 1.4009\n",
            "Epoch 190/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3588 - loss: 1.2846 - val_acc: 0.3138 - val_loss: 1.4015\n",
            "Epoch 191/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3645 - loss: 1.2839 - val_acc: 0.3050 - val_loss: 1.3910\n",
            "Epoch 192/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3615 - loss: 1.2868 - val_acc: 0.2969 - val_loss: 1.3901\n",
            "Epoch 193/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3575 - loss: 1.2825 - val_acc: 0.3044 - val_loss: 1.3953\n",
            "Epoch 194/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3646 - loss: 1.2802 - val_acc: 0.3069 - val_loss: 1.3849\n",
            "Epoch 195/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3619 - loss: 1.2855 - val_acc: 0.3086 - val_loss: 1.4003\n",
            "Epoch 196/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3674 - loss: 1.2754 - val_acc: 0.3061 - val_loss: 1.3903\n",
            "Epoch 197/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3543 - loss: 1.2824 - val_acc: 0.3093 - val_loss: 1.3941\n",
            "Epoch 198/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3640 - loss: 1.2822 - val_acc: 0.2947 - val_loss: 1.3910\n",
            "Epoch 199/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3679 - loss: 1.2804 - val_acc: 0.2969 - val_loss: 1.3886\n",
            "Epoch 200/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3658 - loss: 1.2775 - val_acc: 0.3054 - val_loss: 1.3974\n",
            "Epoch 201/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3650 - loss: 1.2808 - val_acc: 0.3010 - val_loss: 1.3956\n",
            "Epoch 202/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3587 - loss: 1.2799 - val_acc: 0.2967 - val_loss: 1.3990\n",
            "Epoch 203/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3662 - loss: 1.2727 - val_acc: 0.2989 - val_loss: 1.3889\n",
            "Epoch 204/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3659 - loss: 1.2773 - val_acc: 0.3104 - val_loss: 1.4007\n",
            "Epoch 205/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3672 - loss: 1.2739 - val_acc: 0.2907 - val_loss: 1.3934\n",
            "Epoch 206/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3673 - loss: 1.2778 - val_acc: 0.3113 - val_loss: 1.4022\n",
            "Epoch 207/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3622 - loss: 1.2789 - val_acc: 0.3030 - val_loss: 1.3995\n",
            "Epoch 208/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3600 - loss: 1.2788 - val_acc: 0.2912 - val_loss: 1.3894\n",
            "Epoch 209/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3556 - loss: 1.2825 - val_acc: 0.3123 - val_loss: 1.4057\n",
            "Epoch 210/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3630 - loss: 1.2784 - val_acc: 0.3086 - val_loss: 1.3950\n",
            "Epoch 211/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3640 - loss: 1.2739 - val_acc: 0.3080 - val_loss: 1.4065\n",
            "Epoch 212/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3632 - loss: 1.2748 - val_acc: 0.3029 - val_loss: 1.3960\n",
            "Epoch 213/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3703 - loss: 1.2757 - val_acc: 0.3017 - val_loss: 1.3946\n",
            "Epoch 214/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3659 - loss: 1.2771 - val_acc: 0.3100 - val_loss: 1.4076\n",
            "Epoch 215/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3684 - loss: 1.2771 - val_acc: 0.2964 - val_loss: 1.4023\n",
            "Epoch 216/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3640 - loss: 1.2780 - val_acc: 0.3032 - val_loss: 1.4088\n",
            "Epoch 217/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3619 - loss: 1.2778 - val_acc: 0.2977 - val_loss: 1.3929\n",
            "Epoch 218/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3667 - loss: 1.2786 - val_acc: 0.3220 - val_loss: 1.4113\n",
            "Epoch 219/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3699 - loss: 1.2726 - val_acc: 0.3044 - val_loss: 1.4027\n",
            "Epoch 220/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3631 - loss: 1.2753 - val_acc: 0.3080 - val_loss: 1.4155\n",
            "Epoch 221/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3670 - loss: 1.2823 - val_acc: 0.2970 - val_loss: 1.3921\n",
            "Epoch 222/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3645 - loss: 1.2805 - val_acc: 0.2977 - val_loss: 1.4023\n",
            "Epoch 223/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3655 - loss: 1.2698 - val_acc: 0.2932 - val_loss: 1.3916\n",
            "Epoch 224/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3626 - loss: 1.2747 - val_acc: 0.3014 - val_loss: 1.4011\n",
            "Epoch 225/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3680 - loss: 1.2728 - val_acc: 0.3021 - val_loss: 1.4145\n",
            "Epoch 226/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3634 - loss: 1.2747 - val_acc: 0.2929 - val_loss: 1.3941\n",
            "Epoch 227/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3750 - loss: 1.2684 - val_acc: 0.2897 - val_loss: 1.3992\n",
            "Epoch 228/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3655 - loss: 1.2727 - val_acc: 0.2987 - val_loss: 1.4007\n",
            "Epoch 229/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3672 - loss: 1.2707 - val_acc: 0.2998 - val_loss: 1.4135\n",
            "Epoch 230/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3568 - loss: 1.2748 - val_acc: 0.3043 - val_loss: 1.4089\n",
            "Epoch 231/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3696 - loss: 1.2730 - val_acc: 0.3000 - val_loss: 1.4052\n",
            "Epoch 232/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3665 - loss: 1.2699 - val_acc: 0.2995 - val_loss: 1.3986\n",
            "Epoch 233/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3641 - loss: 1.2780 - val_acc: 0.3017 - val_loss: 1.4095\n",
            "Epoch 234/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3670 - loss: 1.2743 - val_acc: 0.2967 - val_loss: 1.3986\n",
            "Epoch 235/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3721 - loss: 1.2684 - val_acc: 0.3006 - val_loss: 1.3963\n",
            "Epoch 236/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3671 - loss: 1.2726 - val_acc: 0.3044 - val_loss: 1.4079\n",
            "Epoch 237/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3685 - loss: 1.2764 - val_acc: 0.3123 - val_loss: 1.4242\n",
            "Epoch 238/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3668 - loss: 1.2718 - val_acc: 0.2998 - val_loss: 1.4030\n",
            "Epoch 239/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3671 - loss: 1.2750 - val_acc: 0.3043 - val_loss: 1.4122\n",
            "Epoch 240/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3679 - loss: 1.2744 - val_acc: 0.3030 - val_loss: 1.3945\n",
            "Epoch 241/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3692 - loss: 1.2715 - val_acc: 0.3104 - val_loss: 1.4149\n",
            "Epoch 242/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3641 - loss: 1.2770 - val_acc: 0.3126 - val_loss: 1.4162\n",
            "Epoch 243/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3648 - loss: 1.2734 - val_acc: 0.2940 - val_loss: 1.4004\n",
            "Epoch 244/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3776 - loss: 1.2665 - val_acc: 0.3038 - val_loss: 1.4050\n",
            "Epoch 245/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3680 - loss: 1.2725 - val_acc: 0.3037 - val_loss: 1.4074\n",
            "Epoch 246/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3701 - loss: 1.2701 - val_acc: 0.3024 - val_loss: 1.4057\n",
            "Epoch 247/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3680 - loss: 1.2719 - val_acc: 0.3024 - val_loss: 1.4018\n",
            "Epoch 248/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3739 - loss: 1.2655 - val_acc: 0.2923 - val_loss: 1.4040\n",
            "Epoch 249/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3718 - loss: 1.2691 - val_acc: 0.3018 - val_loss: 1.4033\n",
            "Epoch 250/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3666 - loss: 1.2669 - val_acc: 0.3023 - val_loss: 1.4089\n",
            "Epoch 251/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3672 - loss: 1.2756 - val_acc: 0.2960 - val_loss: 1.4191\n",
            "Epoch 252/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3760 - loss: 1.2703 - val_acc: 0.2998 - val_loss: 1.4070\n",
            "Epoch 253/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3695 - loss: 1.2674 - val_acc: 0.3004 - val_loss: 1.4082\n",
            "Epoch 254/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3699 - loss: 1.2724 - val_acc: 0.2974 - val_loss: 1.4036\n",
            "Epoch 255/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3745 - loss: 1.2714 - val_acc: 0.3021 - val_loss: 1.3980\n",
            "Epoch 256/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3703 - loss: 1.2672 - val_acc: 0.2972 - val_loss: 1.4051\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 564ms/step\n",
            "Epoch 1/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 127ms/step - acc: 0.2646 - loss: 1.3845 - val_acc: 0.3608 - val_loss: 1.3412\n",
            "Epoch 2/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - acc: 0.3467 - loss: 1.3434 - val_acc: 0.4039 - val_loss: 1.3072\n",
            "Epoch 3/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3867 - loss: 1.3105 - val_acc: 0.4580 - val_loss: 1.2510\n",
            "Epoch 4/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4195 - loss: 1.2713 - val_acc: 0.4712 - val_loss: 1.2331\n",
            "Epoch 5/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4290 - loss: 1.2554 - val_acc: 0.4719 - val_loss: 1.2162\n",
            "Epoch 6/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4387 - loss: 1.2436 - val_acc: 0.4645 - val_loss: 1.2165\n",
            "Epoch 7/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4461 - loss: 1.2391 - val_acc: 0.4776 - val_loss: 1.2090\n",
            "Epoch 8/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4448 - loss: 1.2352 - val_acc: 0.4647 - val_loss: 1.2096\n",
            "Epoch 9/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4514 - loss: 1.2295 - val_acc: 0.4732 - val_loss: 1.2028\n",
            "Epoch 10/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4519 - loss: 1.2262 - val_acc: 0.4734 - val_loss: 1.2005\n",
            "Epoch 11/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4558 - loss: 1.2224 - val_acc: 0.4737 - val_loss: 1.1982\n",
            "Epoch 12/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4563 - loss: 1.2233 - val_acc: 0.4812 - val_loss: 1.1958\n",
            "Epoch 13/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4609 - loss: 1.2184 - val_acc: 0.4798 - val_loss: 1.1954\n",
            "Epoch 14/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4604 - loss: 1.2174 - val_acc: 0.4708 - val_loss: 1.2026\n",
            "Epoch 15/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4590 - loss: 1.2194 - val_acc: 0.4764 - val_loss: 1.1962\n",
            "Epoch 16/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4568 - loss: 1.2215 - val_acc: 0.4812 - val_loss: 1.1881\n",
            "Epoch 17/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4607 - loss: 1.2185 - val_acc: 0.4818 - val_loss: 1.1945\n",
            "Epoch 18/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4600 - loss: 1.2190 - val_acc: 0.4778 - val_loss: 1.1920\n",
            "Epoch 19/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4651 - loss: 1.2095 - val_acc: 0.4827 - val_loss: 1.1901\n",
            "Epoch 20/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4668 - loss: 1.2095 - val_acc: 0.4761 - val_loss: 1.1917\n",
            "Epoch 21/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4614 - loss: 1.2112 - val_acc: 0.4805 - val_loss: 1.1907\n",
            "Epoch 22/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4624 - loss: 1.2121 - val_acc: 0.4780 - val_loss: 1.1941\n",
            "Epoch 23/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4656 - loss: 1.2130 - val_acc: 0.4716 - val_loss: 1.2017\n",
            "Epoch 24/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4659 - loss: 1.2092 - val_acc: 0.4762 - val_loss: 1.1926\n",
            "Epoch 25/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4660 - loss: 1.2069 - val_acc: 0.4742 - val_loss: 1.1977\n",
            "Epoch 26/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4675 - loss: 1.2076 - val_acc: 0.4796 - val_loss: 1.1908\n",
            "Epoch 27/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4637 - loss: 1.2122 - val_acc: 0.4822 - val_loss: 1.1886\n",
            "Epoch 28/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4668 - loss: 1.2103 - val_acc: 0.4767 - val_loss: 1.1877\n",
            "Epoch 29/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4621 - loss: 1.2117 - val_acc: 0.4813 - val_loss: 1.1932\n",
            "Epoch 30/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4639 - loss: 1.2075 - val_acc: 0.4829 - val_loss: 1.1879\n",
            "Epoch 31/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4710 - loss: 1.2049 - val_acc: 0.4792 - val_loss: 1.1910\n",
            "Epoch 32/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4629 - loss: 1.2122 - val_acc: 0.4774 - val_loss: 1.1885\n",
            "Epoch 33/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4635 - loss: 1.2102 - val_acc: 0.4798 - val_loss: 1.1874\n",
            "Epoch 34/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4626 - loss: 1.2098 - val_acc: 0.4760 - val_loss: 1.1852\n",
            "Epoch 35/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4672 - loss: 1.2080 - val_acc: 0.4773 - val_loss: 1.1962\n",
            "Epoch 36/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - acc: 0.4642 - loss: 1.2120 - val_acc: 0.4768 - val_loss: 1.1902\n",
            "Epoch 37/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4708 - loss: 1.2020 - val_acc: 0.4746 - val_loss: 1.1921\n",
            "Epoch 38/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4670 - loss: 1.2068 - val_acc: 0.4757 - val_loss: 1.1886\n",
            "Epoch 39/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4714 - loss: 1.2059 - val_acc: 0.4728 - val_loss: 1.2038\n",
            "Epoch 40/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4654 - loss: 1.2088 - val_acc: 0.4803 - val_loss: 1.1839\n",
            "Epoch 41/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4708 - loss: 1.2037 - val_acc: 0.4759 - val_loss: 1.1847\n",
            "Epoch 42/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4678 - loss: 1.2011 - val_acc: 0.4824 - val_loss: 1.1894\n",
            "Epoch 43/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4689 - loss: 1.2072 - val_acc: 0.4837 - val_loss: 1.1863\n",
            "Epoch 44/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4687 - loss: 1.2049 - val_acc: 0.4729 - val_loss: 1.1903\n",
            "Epoch 45/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4690 - loss: 1.1994 - val_acc: 0.4773 - val_loss: 1.1895\n",
            "Epoch 46/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4687 - loss: 1.2009 - val_acc: 0.4723 - val_loss: 1.1973\n",
            "Epoch 47/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4687 - loss: 1.2063 - val_acc: 0.4813 - val_loss: 1.1825\n",
            "Epoch 48/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4689 - loss: 1.2037 - val_acc: 0.4805 - val_loss: 1.1906\n",
            "Epoch 49/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4696 - loss: 1.2003 - val_acc: 0.4822 - val_loss: 1.1905\n",
            "Epoch 50/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4720 - loss: 1.2028 - val_acc: 0.4831 - val_loss: 1.1814\n",
            "Epoch 51/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4703 - loss: 1.2047 - val_acc: 0.4735 - val_loss: 1.1927\n",
            "Epoch 52/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4742 - loss: 1.2006 - val_acc: 0.4753 - val_loss: 1.1857\n",
            "Epoch 53/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4708 - loss: 1.1983 - val_acc: 0.4777 - val_loss: 1.1851\n",
            "Epoch 54/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4727 - loss: 1.1980 - val_acc: 0.4787 - val_loss: 1.1890\n",
            "Epoch 55/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4720 - loss: 1.2024 - val_acc: 0.4792 - val_loss: 1.1829\n",
            "Epoch 56/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4718 - loss: 1.2016 - val_acc: 0.4775 - val_loss: 1.1851\n",
            "Epoch 57/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4714 - loss: 1.2025 - val_acc: 0.4795 - val_loss: 1.1882\n",
            "Epoch 58/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4726 - loss: 1.1995 - val_acc: 0.4695 - val_loss: 1.1898\n",
            "Epoch 59/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4747 - loss: 1.1972 - val_acc: 0.4786 - val_loss: 1.1835\n",
            "Epoch 60/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4717 - loss: 1.1995 - val_acc: 0.4726 - val_loss: 1.1905\n",
            "Epoch 61/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4689 - loss: 1.2046 - val_acc: 0.4757 - val_loss: 1.1835\n",
            "Epoch 62/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4742 - loss: 1.1958 - val_acc: 0.4822 - val_loss: 1.1826\n",
            "Epoch 63/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4725 - loss: 1.1965 - val_acc: 0.4741 - val_loss: 1.1864\n",
            "Epoch 64/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4681 - loss: 1.2027 - val_acc: 0.4846 - val_loss: 1.1841\n",
            "Epoch 65/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4711 - loss: 1.1957 - val_acc: 0.4800 - val_loss: 1.1825\n",
            "Epoch 66/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4770 - loss: 1.1946 - val_acc: 0.4797 - val_loss: 1.1842\n",
            "Epoch 67/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4743 - loss: 1.1970 - val_acc: 0.4820 - val_loss: 1.1824\n",
            "Epoch 68/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4767 - loss: 1.1954 - val_acc: 0.4815 - val_loss: 1.1839\n",
            "Epoch 69/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4751 - loss: 1.1958 - val_acc: 0.4812 - val_loss: 1.1801\n",
            "Epoch 70/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4748 - loss: 1.1979 - val_acc: 0.4836 - val_loss: 1.1781\n",
            "Epoch 71/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4705 - loss: 1.1986 - val_acc: 0.4832 - val_loss: 1.1811\n",
            "Epoch 72/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4785 - loss: 1.1953 - val_acc: 0.4781 - val_loss: 1.1887\n",
            "Epoch 73/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4750 - loss: 1.1989 - val_acc: 0.4785 - val_loss: 1.1859\n",
            "Epoch 74/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4727 - loss: 1.1969 - val_acc: 0.4822 - val_loss: 1.1808\n",
            "Epoch 75/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4760 - loss: 1.1922 - val_acc: 0.4817 - val_loss: 1.1807\n",
            "Epoch 76/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4719 - loss: 1.1976 - val_acc: 0.4768 - val_loss: 1.1860\n",
            "Epoch 77/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4717 - loss: 1.1959 - val_acc: 0.4832 - val_loss: 1.1825\n",
            "Epoch 78/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4725 - loss: 1.1963 - val_acc: 0.4824 - val_loss: 1.1847\n",
            "Epoch 79/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4771 - loss: 1.1931 - val_acc: 0.4823 - val_loss: 1.1839\n",
            "Epoch 80/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4715 - loss: 1.1983 - val_acc: 0.4768 - val_loss: 1.1891\n",
            "Epoch 81/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4690 - loss: 1.1978 - val_acc: 0.4865 - val_loss: 1.1844\n",
            "Epoch 82/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4765 - loss: 1.1926 - val_acc: 0.4877 - val_loss: 1.1844\n",
            "Epoch 83/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4738 - loss: 1.1980 - val_acc: 0.4781 - val_loss: 1.1853\n",
            "Epoch 84/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4758 - loss: 1.1950 - val_acc: 0.4818 - val_loss: 1.1893\n",
            "Epoch 85/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4730 - loss: 1.1966 - val_acc: 0.4828 - val_loss: 1.1831\n",
            "Epoch 86/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4782 - loss: 1.1888 - val_acc: 0.4798 - val_loss: 1.1834\n",
            "Epoch 87/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4712 - loss: 1.1984 - val_acc: 0.4800 - val_loss: 1.1817\n",
            "Epoch 88/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4777 - loss: 1.1905 - val_acc: 0.4801 - val_loss: 1.1871\n",
            "Epoch 89/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4744 - loss: 1.1935 - val_acc: 0.4810 - val_loss: 1.1886\n",
            "Epoch 90/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4752 - loss: 1.1925 - val_acc: 0.4845 - val_loss: 1.1837\n",
            "Epoch 91/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4724 - loss: 1.1979 - val_acc: 0.4798 - val_loss: 1.1867\n",
            "Epoch 92/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4802 - loss: 1.1929 - val_acc: 0.4807 - val_loss: 1.1873\n",
            "Epoch 93/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4771 - loss: 1.1889 - val_acc: 0.4879 - val_loss: 1.1875\n",
            "Epoch 94/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4737 - loss: 1.1953 - val_acc: 0.4822 - val_loss: 1.1823\n",
            "Epoch 95/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4766 - loss: 1.1920 - val_acc: 0.4780 - val_loss: 1.1904\n",
            "Epoch 96/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4732 - loss: 1.1939 - val_acc: 0.4791 - val_loss: 1.1805\n",
            "Epoch 97/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4811 - loss: 1.1912 - val_acc: 0.4803 - val_loss: 1.1868\n",
            "Epoch 98/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4702 - loss: 1.1971 - val_acc: 0.4811 - val_loss: 1.1847\n",
            "Epoch 99/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4746 - loss: 1.1943 - val_acc: 0.4821 - val_loss: 1.1876\n",
            "Epoch 100/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4723 - loss: 1.1951 - val_acc: 0.4820 - val_loss: 1.1895\n",
            "Epoch 101/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4760 - loss: 1.1940 - val_acc: 0.4790 - val_loss: 1.1892\n",
            "Epoch 102/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4707 - loss: 1.1946 - val_acc: 0.4796 - val_loss: 1.1885\n",
            "Epoch 103/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4769 - loss: 1.1917 - val_acc: 0.4854 - val_loss: 1.1850\n",
            "Epoch 104/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4750 - loss: 1.1918 - val_acc: 0.4842 - val_loss: 1.1832\n",
            "Epoch 105/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4766 - loss: 1.1911 - val_acc: 0.4789 - val_loss: 1.1867\n",
            "Epoch 106/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4751 - loss: 1.1932 - val_acc: 0.4803 - val_loss: 1.1872\n",
            "Epoch 107/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4706 - loss: 1.1944 - val_acc: 0.4817 - val_loss: 1.1839\n",
            "Epoch 108/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4725 - loss: 1.1952 - val_acc: 0.4830 - val_loss: 1.1815\n",
            "Epoch 109/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4739 - loss: 1.1894 - val_acc: 0.4839 - val_loss: 1.1845\n",
            "Epoch 110/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4725 - loss: 1.1927 - val_acc: 0.4786 - val_loss: 1.1906\n",
            "Epoch 111/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4753 - loss: 1.1908 - val_acc: 0.4837 - val_loss: 1.1820\n",
            "Epoch 112/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4753 - loss: 1.1870 - val_acc: 0.4783 - val_loss: 1.1864\n",
            "Epoch 113/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4727 - loss: 1.1926 - val_acc: 0.4841 - val_loss: 1.1836\n",
            "Epoch 114/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4691 - loss: 1.1954 - val_acc: 0.4848 - val_loss: 1.1840\n",
            "Epoch 115/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4766 - loss: 1.1885 - val_acc: 0.4801 - val_loss: 1.1880\n",
            "Epoch 116/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4777 - loss: 1.1912 - val_acc: 0.4794 - val_loss: 1.1846\n",
            "Epoch 117/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4738 - loss: 1.1916 - val_acc: 0.4808 - val_loss: 1.1833\n",
            "Epoch 118/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4740 - loss: 1.1836 - val_acc: 0.4854 - val_loss: 1.1856\n",
            "Epoch 119/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4787 - loss: 1.1872 - val_acc: 0.4781 - val_loss: 1.1884\n",
            "Epoch 120/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4825 - loss: 1.1822 - val_acc: 0.4802 - val_loss: 1.1891\n",
            "Epoch 121/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4728 - loss: 1.1932 - val_acc: 0.4772 - val_loss: 1.1882\n",
            "Epoch 122/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4775 - loss: 1.1895 - val_acc: 0.4823 - val_loss: 1.1826\n",
            "Epoch 123/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4735 - loss: 1.1921 - val_acc: 0.4797 - val_loss: 1.1880\n",
            "Epoch 124/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4754 - loss: 1.1891 - val_acc: 0.4779 - val_loss: 1.1874\n",
            "Epoch 125/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4759 - loss: 1.1881 - val_acc: 0.4820 - val_loss: 1.1866\n",
            "Epoch 126/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4748 - loss: 1.1925 - val_acc: 0.4862 - val_loss: 1.1875\n",
            "Epoch 127/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4786 - loss: 1.1854 - val_acc: 0.4842 - val_loss: 1.1856\n",
            "Epoch 128/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4754 - loss: 1.1912 - val_acc: 0.4782 - val_loss: 1.1849\n",
            "Epoch 129/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4744 - loss: 1.1916 - val_acc: 0.4765 - val_loss: 1.1885\n",
            "Epoch 130/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4748 - loss: 1.1904 - val_acc: 0.4777 - val_loss: 1.1923\n",
            "Epoch 131/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4792 - loss: 1.1862 - val_acc: 0.4801 - val_loss: 1.1918\n",
            "Epoch 132/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4708 - loss: 1.1933 - val_acc: 0.4798 - val_loss: 1.1870\n",
            "Epoch 133/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4797 - loss: 1.1847 - val_acc: 0.4805 - val_loss: 1.1881\n",
            "Epoch 134/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4786 - loss: 1.1865 - val_acc: 0.4754 - val_loss: 1.1890\n",
            "Epoch 135/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4723 - loss: 1.1939 - val_acc: 0.4793 - val_loss: 1.1855\n",
            "Epoch 136/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4823 - loss: 1.1785 - val_acc: 0.4816 - val_loss: 1.1901\n",
            "Epoch 137/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4740 - loss: 1.1873 - val_acc: 0.4797 - val_loss: 1.1895\n",
            "Epoch 138/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4799 - loss: 1.1838 - val_acc: 0.4776 - val_loss: 1.1911\n",
            "Epoch 139/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4740 - loss: 1.1912 - val_acc: 0.4775 - val_loss: 1.1905\n",
            "Epoch 140/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4795 - loss: 1.1861 - val_acc: 0.4762 - val_loss: 1.1933\n",
            "Epoch 141/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4775 - loss: 1.1895 - val_acc: 0.4759 - val_loss: 1.1870\n",
            "Epoch 142/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4826 - loss: 1.1796 - val_acc: 0.4786 - val_loss: 1.1912\n",
            "Epoch 143/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4772 - loss: 1.1858 - val_acc: 0.4814 - val_loss: 1.1901\n",
            "Epoch 144/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4794 - loss: 1.1841 - val_acc: 0.4764 - val_loss: 1.1908\n",
            "Epoch 145/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4796 - loss: 1.1796 - val_acc: 0.4788 - val_loss: 1.1958\n",
            "Epoch 146/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4836 - loss: 1.1835 - val_acc: 0.4802 - val_loss: 1.1876\n",
            "Epoch 147/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4742 - loss: 1.1864 - val_acc: 0.4806 - val_loss: 1.1910\n",
            "Epoch 148/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4773 - loss: 1.1867 - val_acc: 0.4809 - val_loss: 1.1941\n",
            "Epoch 149/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4814 - loss: 1.1857 - val_acc: 0.4795 - val_loss: 1.1947\n",
            "Epoch 150/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4812 - loss: 1.1788 - val_acc: 0.4798 - val_loss: 1.1858\n",
            "Epoch 151/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4847 - loss: 1.1807 - val_acc: 0.4785 - val_loss: 1.1913\n",
            "Epoch 152/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4770 - loss: 1.1841 - val_acc: 0.4768 - val_loss: 1.1909\n",
            "Epoch 153/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4785 - loss: 1.1825 - val_acc: 0.4762 - val_loss: 1.1872\n",
            "Epoch 154/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4814 - loss: 1.1823 - val_acc: 0.4797 - val_loss: 1.1904\n",
            "Epoch 155/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4797 - loss: 1.1806 - val_acc: 0.4722 - val_loss: 1.1933\n",
            "Epoch 156/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4778 - loss: 1.1821 - val_acc: 0.4724 - val_loss: 1.1942\n",
            "Epoch 157/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4743 - loss: 1.1880 - val_acc: 0.4809 - val_loss: 1.1933\n",
            "Epoch 158/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4795 - loss: 1.1820 - val_acc: 0.4748 - val_loss: 1.2012\n",
            "Epoch 159/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4809 - loss: 1.1805 - val_acc: 0.4734 - val_loss: 1.1909\n",
            "Epoch 160/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4791 - loss: 1.1856 - val_acc: 0.4744 - val_loss: 1.1948\n",
            "Epoch 161/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4817 - loss: 1.1811 - val_acc: 0.4849 - val_loss: 1.1910\n",
            "Epoch 162/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4800 - loss: 1.1818 - val_acc: 0.4761 - val_loss: 1.1926\n",
            "Epoch 163/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4798 - loss: 1.1831 - val_acc: 0.4782 - val_loss: 1.1961\n",
            "Epoch 164/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4760 - loss: 1.1839 - val_acc: 0.4736 - val_loss: 1.1927\n",
            "Epoch 165/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4789 - loss: 1.1855 - val_acc: 0.4813 - val_loss: 1.1927\n",
            "Epoch 166/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4809 - loss: 1.1828 - val_acc: 0.4793 - val_loss: 1.1938\n",
            "Epoch 167/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4853 - loss: 1.1773 - val_acc: 0.4715 - val_loss: 1.1940\n",
            "Epoch 168/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4826 - loss: 1.1763 - val_acc: 0.4841 - val_loss: 1.1948\n",
            "Epoch 169/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4825 - loss: 1.1770 - val_acc: 0.4747 - val_loss: 1.1937\n",
            "Epoch 170/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4793 - loss: 1.1811 - val_acc: 0.4823 - val_loss: 1.1935\n",
            "Epoch 171/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4819 - loss: 1.1808 - val_acc: 0.4782 - val_loss: 1.1977\n",
            "Epoch 172/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4799 - loss: 1.1807 - val_acc: 0.4796 - val_loss: 1.1925\n",
            "Epoch 173/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4787 - loss: 1.1841 - val_acc: 0.4745 - val_loss: 1.1995\n",
            "Epoch 174/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4805 - loss: 1.1792 - val_acc: 0.4768 - val_loss: 1.2063\n",
            "Epoch 175/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4829 - loss: 1.1767 - val_acc: 0.4782 - val_loss: 1.1942\n",
            "Epoch 176/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4773 - loss: 1.1824 - val_acc: 0.4802 - val_loss: 1.1937\n",
            "Epoch 177/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4821 - loss: 1.1824 - val_acc: 0.4811 - val_loss: 1.1973\n",
            "Epoch 178/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4791 - loss: 1.1807 - val_acc: 0.4812 - val_loss: 1.1944\n",
            "Epoch 179/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4817 - loss: 1.1789 - val_acc: 0.4758 - val_loss: 1.1946\n",
            "Epoch 180/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4830 - loss: 1.1753 - val_acc: 0.4811 - val_loss: 1.1951\n",
            "Epoch 181/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4825 - loss: 1.1797 - val_acc: 0.4799 - val_loss: 1.1984\n",
            "Epoch 182/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4851 - loss: 1.1745 - val_acc: 0.4778 - val_loss: 1.1997\n",
            "Epoch 183/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4846 - loss: 1.1748 - val_acc: 0.4722 - val_loss: 1.1954\n",
            "Epoch 184/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4816 - loss: 1.1780 - val_acc: 0.4768 - val_loss: 1.1995\n",
            "Epoch 185/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4859 - loss: 1.1769 - val_acc: 0.4763 - val_loss: 1.1939\n",
            "Epoch 186/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4797 - loss: 1.1783 - val_acc: 0.4761 - val_loss: 1.1967\n",
            "Epoch 187/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4794 - loss: 1.1797 - val_acc: 0.4764 - val_loss: 1.2003\n",
            "Epoch 188/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4846 - loss: 1.1743 - val_acc: 0.4750 - val_loss: 1.2031\n",
            "Epoch 189/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4831 - loss: 1.1819 - val_acc: 0.4799 - val_loss: 1.1984\n",
            "Epoch 190/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4809 - loss: 1.1794 - val_acc: 0.4753 - val_loss: 1.1988\n",
            "Epoch 191/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4846 - loss: 1.1743 - val_acc: 0.4734 - val_loss: 1.2071\n",
            "Epoch 192/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4805 - loss: 1.1781 - val_acc: 0.4689 - val_loss: 1.2064\n",
            "Epoch 193/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4830 - loss: 1.1781 - val_acc: 0.4772 - val_loss: 1.1993\n",
            "Epoch 194/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4786 - loss: 1.1781 - val_acc: 0.4731 - val_loss: 1.2039\n",
            "Epoch 195/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4821 - loss: 1.1768 - val_acc: 0.4766 - val_loss: 1.1946\n",
            "Epoch 196/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4763 - loss: 1.1835 - val_acc: 0.4729 - val_loss: 1.1987\n",
            "Epoch 197/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4804 - loss: 1.1808 - val_acc: 0.4777 - val_loss: 1.1971\n",
            "Epoch 198/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4823 - loss: 1.1774 - val_acc: 0.4757 - val_loss: 1.1947\n",
            "Epoch 199/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4799 - loss: 1.1786 - val_acc: 0.4769 - val_loss: 1.2012\n",
            "Epoch 200/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4838 - loss: 1.1744 - val_acc: 0.4793 - val_loss: 1.2000\n",
            "Epoch 201/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4836 - loss: 1.1750 - val_acc: 0.4771 - val_loss: 1.2007\n",
            "Epoch 202/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4872 - loss: 1.1737 - val_acc: 0.4742 - val_loss: 1.2029\n",
            "Epoch 203/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4825 - loss: 1.1768 - val_acc: 0.4777 - val_loss: 1.1965\n",
            "Epoch 204/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4873 - loss: 1.1706 - val_acc: 0.4807 - val_loss: 1.1991\n",
            "Epoch 205/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4817 - loss: 1.1753 - val_acc: 0.4723 - val_loss: 1.1989\n",
            "Epoch 206/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4827 - loss: 1.1773 - val_acc: 0.4743 - val_loss: 1.2018\n",
            "Epoch 207/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4816 - loss: 1.1810 - val_acc: 0.4767 - val_loss: 1.1995\n",
            "Epoch 208/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4833 - loss: 1.1716 - val_acc: 0.4767 - val_loss: 1.2039\n",
            "Epoch 209/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4850 - loss: 1.1701 - val_acc: 0.4777 - val_loss: 1.2020\n",
            "Epoch 210/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4871 - loss: 1.1724 - val_acc: 0.4785 - val_loss: 1.2041\n",
            "Epoch 211/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4840 - loss: 1.1751 - val_acc: 0.4745 - val_loss: 1.2015\n",
            "Epoch 212/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4852 - loss: 1.1725 - val_acc: 0.4758 - val_loss: 1.2012\n",
            "Epoch 213/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4832 - loss: 1.1705 - val_acc: 0.4746 - val_loss: 1.2003\n",
            "Epoch 214/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4848 - loss: 1.1769 - val_acc: 0.4778 - val_loss: 1.2023\n",
            "Epoch 215/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4843 - loss: 1.1724 - val_acc: 0.4782 - val_loss: 1.1952\n",
            "Epoch 216/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4845 - loss: 1.1770 - val_acc: 0.4750 - val_loss: 1.2057\n",
            "Epoch 217/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4903 - loss: 1.1683 - val_acc: 0.4713 - val_loss: 1.2103\n",
            "Epoch 218/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4886 - loss: 1.1695 - val_acc: 0.4753 - val_loss: 1.2023\n",
            "Epoch 219/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4795 - loss: 1.1791 - val_acc: 0.4784 - val_loss: 1.2053\n",
            "Epoch 220/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4795 - loss: 1.1762 - val_acc: 0.4710 - val_loss: 1.2044\n",
            "Epoch 221/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4856 - loss: 1.1695 - val_acc: 0.4753 - val_loss: 1.2065\n",
            "Epoch 222/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4843 - loss: 1.1723 - val_acc: 0.4723 - val_loss: 1.2140\n",
            "Epoch 223/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4811 - loss: 1.1783 - val_acc: 0.4769 - val_loss: 1.2007\n",
            "Epoch 224/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4835 - loss: 1.1755 - val_acc: 0.4789 - val_loss: 1.1995\n",
            "Epoch 225/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4869 - loss: 1.1716 - val_acc: 0.4773 - val_loss: 1.1980\n",
            "Epoch 226/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4864 - loss: 1.1721 - val_acc: 0.4768 - val_loss: 1.2006\n",
            "Epoch 227/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4839 - loss: 1.1765 - val_acc: 0.4842 - val_loss: 1.2021\n",
            "Epoch 228/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4864 - loss: 1.1698 - val_acc: 0.4786 - val_loss: 1.2041\n",
            "Epoch 229/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4902 - loss: 1.1667 - val_acc: 0.4730 - val_loss: 1.2070\n",
            "Epoch 230/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4844 - loss: 1.1718 - val_acc: 0.4798 - val_loss: 1.2020\n",
            "Epoch 231/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4859 - loss: 1.1718 - val_acc: 0.4723 - val_loss: 1.2049\n",
            "Epoch 232/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4783 - loss: 1.1748 - val_acc: 0.4793 - val_loss: 1.2044\n",
            "Epoch 233/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4844 - loss: 1.1725 - val_acc: 0.4776 - val_loss: 1.1989\n",
            "Epoch 234/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4831 - loss: 1.1725 - val_acc: 0.4756 - val_loss: 1.2009\n",
            "Epoch 235/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4801 - loss: 1.1764 - val_acc: 0.4763 - val_loss: 1.2039\n",
            "Epoch 236/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4842 - loss: 1.1724 - val_acc: 0.4728 - val_loss: 1.2033\n",
            "Epoch 237/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4883 - loss: 1.1661 - val_acc: 0.4776 - val_loss: 1.2009\n",
            "Epoch 238/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4864 - loss: 1.1684 - val_acc: 0.4754 - val_loss: 1.2030\n",
            "Epoch 239/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4823 - loss: 1.1758 - val_acc: 0.4719 - val_loss: 1.2057\n",
            "Epoch 240/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4832 - loss: 1.1731 - val_acc: 0.4728 - val_loss: 1.2023\n",
            "Epoch 241/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4809 - loss: 1.1727 - val_acc: 0.4783 - val_loss: 1.2076\n",
            "Epoch 242/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4864 - loss: 1.1718 - val_acc: 0.4771 - val_loss: 1.2078\n",
            "Epoch 243/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4898 - loss: 1.1646 - val_acc: 0.4752 - val_loss: 1.2029\n",
            "Epoch 244/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4830 - loss: 1.1727 - val_acc: 0.4692 - val_loss: 1.2071\n",
            "Epoch 245/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4831 - loss: 1.1766 - val_acc: 0.4748 - val_loss: 1.2067\n",
            "Epoch 246/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4859 - loss: 1.1690 - val_acc: 0.4727 - val_loss: 1.2046\n",
            "Epoch 247/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4857 - loss: 1.1683 - val_acc: 0.4735 - val_loss: 1.2010\n",
            "Epoch 248/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4892 - loss: 1.1659 - val_acc: 0.4754 - val_loss: 1.2029\n",
            "Epoch 249/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4817 - loss: 1.1769 - val_acc: 0.4788 - val_loss: 1.2020\n",
            "Epoch 250/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4831 - loss: 1.1716 - val_acc: 0.4803 - val_loss: 1.2018\n",
            "Epoch 251/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4828 - loss: 1.1752 - val_acc: 0.4714 - val_loss: 1.2072\n",
            "Epoch 252/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4860 - loss: 1.1707 - val_acc: 0.4771 - val_loss: 1.2048\n",
            "Epoch 253/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4825 - loss: 1.1708 - val_acc: 0.4796 - val_loss: 1.2044\n",
            "Epoch 254/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4839 - loss: 1.1759 - val_acc: 0.4744 - val_loss: 1.2087\n",
            "Epoch 255/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4880 - loss: 1.1673 - val_acc: 0.4749 - val_loss: 1.2075\n",
            "Epoch 256/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4818 - loss: 1.1766 - val_acc: 0.4757 - val_loss: 1.2047\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 280ms/step\n",
            "Epoch 1/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 238ms/step - acc: 0.2473 - loss: 1.3871 - val_acc: 0.2500 - val_loss: 1.3861\n",
            "Epoch 2/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - acc: 0.2492 - loss: 1.3863 - val_acc: 0.2685 - val_loss: 1.3859\n",
            "Epoch 3/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.2555 - loss: 1.3860 - val_acc: 0.2648 - val_loss: 1.3858\n",
            "Epoch 4/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.2589 - loss: 1.3860 - val_acc: 0.2780 - val_loss: 1.3843\n",
            "Epoch 5/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2685 - loss: 1.3840 - val_acc: 0.2950 - val_loss: 1.3803\n",
            "Epoch 6/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2750 - loss: 1.3819 - val_acc: 0.2872 - val_loss: 1.3784\n",
            "Epoch 7/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2807 - loss: 1.3798 - val_acc: 0.3050 - val_loss: 1.3769\n",
            "Epoch 8/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2903 - loss: 1.3773 - val_acc: 0.2972 - val_loss: 1.3767\n",
            "Epoch 9/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2841 - loss: 1.3780 - val_acc: 0.3126 - val_loss: 1.3755\n",
            "Epoch 10/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2816 - loss: 1.3770 - val_acc: 0.3090 - val_loss: 1.3759\n",
            "Epoch 11/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2790 - loss: 1.3763 - val_acc: 0.2911 - val_loss: 1.3760\n",
            "Epoch 12/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.2829 - loss: 1.3749 - val_acc: 0.3170 - val_loss: 1.3741\n",
            "Epoch 13/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.2866 - loss: 1.3746 - val_acc: 0.2992 - val_loss: 1.3761\n",
            "Epoch 14/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2880 - loss: 1.3748 - val_acc: 0.2920 - val_loss: 1.3772\n",
            "Epoch 15/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2838 - loss: 1.3755 - val_acc: 0.3030 - val_loss: 1.3754\n",
            "Epoch 16/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2865 - loss: 1.3742 - val_acc: 0.3054 - val_loss: 1.3753\n",
            "Epoch 17/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2940 - loss: 1.3739 - val_acc: 0.3060 - val_loss: 1.3756\n",
            "Epoch 18/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2920 - loss: 1.3732 - val_acc: 0.3050 - val_loss: 1.3751\n",
            "Epoch 19/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2882 - loss: 1.3727 - val_acc: 0.2984 - val_loss: 1.3757\n",
            "Epoch 20/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2943 - loss: 1.3733 - val_acc: 0.3049 - val_loss: 1.3764\n",
            "Epoch 21/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.2883 - loss: 1.3728 - val_acc: 0.3067 - val_loss: 1.3760\n",
            "Epoch 22/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.2886 - loss: 1.3722 - val_acc: 0.3073 - val_loss: 1.3743\n",
            "Epoch 23/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2941 - loss: 1.3712 - val_acc: 0.3057 - val_loss: 1.3739\n",
            "Epoch 24/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3002 - loss: 1.3711 - val_acc: 0.3069 - val_loss: 1.3730\n",
            "Epoch 25/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3001 - loss: 1.3714 - val_acc: 0.3012 - val_loss: 1.3734\n",
            "Epoch 26/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2958 - loss: 1.3727 - val_acc: 0.2983 - val_loss: 1.3725\n",
            "Epoch 27/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2974 - loss: 1.3712 - val_acc: 0.3093 - val_loss: 1.3699\n",
            "Epoch 28/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.2926 - loss: 1.3727 - val_acc: 0.3009 - val_loss: 1.3713\n",
            "Epoch 29/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3000 - loss: 1.3699 - val_acc: 0.3057 - val_loss: 1.3692\n",
            "Epoch 30/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3060 - loss: 1.3684 - val_acc: 0.3038 - val_loss: 1.3679\n",
            "Epoch 31/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3080 - loss: 1.3673 - val_acc: 0.3030 - val_loss: 1.3668\n",
            "Epoch 32/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3059 - loss: 1.3690 - val_acc: 0.3106 - val_loss: 1.3674\n",
            "Epoch 33/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3021 - loss: 1.3689 - val_acc: 0.3057 - val_loss: 1.3653\n",
            "Epoch 34/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3086 - loss: 1.3684 - val_acc: 0.3067 - val_loss: 1.3640\n",
            "Epoch 35/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3132 - loss: 1.3659 - val_acc: 0.3210 - val_loss: 1.3631\n",
            "Epoch 36/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3028 - loss: 1.3688 - val_acc: 0.3238 - val_loss: 1.3633\n",
            "Epoch 37/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3071 - loss: 1.3688 - val_acc: 0.3109 - val_loss: 1.3616\n",
            "Epoch 38/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3097 - loss: 1.3661 - val_acc: 0.3117 - val_loss: 1.3605\n",
            "Epoch 39/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3047 - loss: 1.3690 - val_acc: 0.2966 - val_loss: 1.3604\n",
            "Epoch 40/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3164 - loss: 1.3637 - val_acc: 0.3126 - val_loss: 1.3599\n",
            "Epoch 41/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3108 - loss: 1.3656 - val_acc: 0.3160 - val_loss: 1.3595\n",
            "Epoch 42/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3151 - loss: 1.3658 - val_acc: 0.3189 - val_loss: 1.3567\n",
            "Epoch 43/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3142 - loss: 1.3661 - val_acc: 0.3187 - val_loss: 1.3550\n",
            "Epoch 44/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3201 - loss: 1.3624 - val_acc: 0.3146 - val_loss: 1.3557\n",
            "Epoch 45/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3180 - loss: 1.3631 - val_acc: 0.3200 - val_loss: 1.3540\n",
            "Epoch 46/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3200 - loss: 1.3628 - val_acc: 0.3167 - val_loss: 1.3551\n",
            "Epoch 47/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3206 - loss: 1.3614 - val_acc: 0.3249 - val_loss: 1.3552\n",
            "Epoch 48/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3265 - loss: 1.3593 - val_acc: 0.3272 - val_loss: 1.3534\n",
            "Epoch 49/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3190 - loss: 1.3617 - val_acc: 0.3267 - val_loss: 1.3526\n",
            "Epoch 50/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3241 - loss: 1.3615 - val_acc: 0.3312 - val_loss: 1.3539\n",
            "Epoch 51/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.3210 - loss: 1.3632 - val_acc: 0.3267 - val_loss: 1.3502\n",
            "Epoch 52/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3207 - loss: 1.3602 - val_acc: 0.3310 - val_loss: 1.3509\n",
            "Epoch 53/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3259 - loss: 1.3585 - val_acc: 0.3240 - val_loss: 1.3513\n",
            "Epoch 54/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3231 - loss: 1.3626 - val_acc: 0.3332 - val_loss: 1.3531\n",
            "Epoch 55/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3217 - loss: 1.3605 - val_acc: 0.3287 - val_loss: 1.3519\n",
            "Epoch 56/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3225 - loss: 1.3600 - val_acc: 0.3418 - val_loss: 1.3522\n",
            "Epoch 57/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3270 - loss: 1.3583 - val_acc: 0.3295 - val_loss: 1.3517\n",
            "Epoch 58/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3265 - loss: 1.3601 - val_acc: 0.3312 - val_loss: 1.3532\n",
            "Epoch 59/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3175 - loss: 1.3604 - val_acc: 0.3263 - val_loss: 1.3534\n",
            "Epoch 60/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3233 - loss: 1.3595 - val_acc: 0.3332 - val_loss: 1.3519\n",
            "Epoch 61/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3276 - loss: 1.3556 - val_acc: 0.3335 - val_loss: 1.3508\n",
            "Epoch 62/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3221 - loss: 1.3622 - val_acc: 0.3419 - val_loss: 1.3514\n",
            "Epoch 63/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3264 - loss: 1.3576 - val_acc: 0.3316 - val_loss: 1.3515\n",
            "Epoch 64/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3238 - loss: 1.3578 - val_acc: 0.3343 - val_loss: 1.3522\n",
            "Epoch 65/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3211 - loss: 1.3579 - val_acc: 0.3398 - val_loss: 1.3504\n",
            "Epoch 66/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3296 - loss: 1.3570 - val_acc: 0.3318 - val_loss: 1.3488\n",
            "Epoch 67/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3302 - loss: 1.3549 - val_acc: 0.3327 - val_loss: 1.3517\n",
            "Epoch 68/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3235 - loss: 1.3576 - val_acc: 0.3339 - val_loss: 1.3511\n",
            "Epoch 69/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3202 - loss: 1.3585 - val_acc: 0.3284 - val_loss: 1.3504\n",
            "Epoch 70/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.3313 - loss: 1.3552 - val_acc: 0.3350 - val_loss: 1.3481\n",
            "Epoch 71/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.3338 - loss: 1.3519 - val_acc: 0.3307 - val_loss: 1.3525\n",
            "Epoch 72/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3252 - loss: 1.3555 - val_acc: 0.3416 - val_loss: 1.3514\n",
            "Epoch 73/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3270 - loss: 1.3560 - val_acc: 0.3370 - val_loss: 1.3508\n",
            "Epoch 74/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3255 - loss: 1.3592 - val_acc: 0.3409 - val_loss: 1.3479\n",
            "Epoch 75/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3251 - loss: 1.3570 - val_acc: 0.3253 - val_loss: 1.3498\n",
            "Epoch 76/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3306 - loss: 1.3540 - val_acc: 0.3492 - val_loss: 1.3526\n",
            "Epoch 77/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3300 - loss: 1.3563 - val_acc: 0.3356 - val_loss: 1.3498\n",
            "Epoch 78/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3193 - loss: 1.3590 - val_acc: 0.3344 - val_loss: 1.3480\n",
            "Epoch 79/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3259 - loss: 1.3534 - val_acc: 0.3413 - val_loss: 1.3489\n",
            "Epoch 80/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3271 - loss: 1.3551 - val_acc: 0.3435 - val_loss: 1.3482\n",
            "Epoch 81/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3325 - loss: 1.3532 - val_acc: 0.3332 - val_loss: 1.3529\n",
            "Epoch 82/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3266 - loss: 1.3540 - val_acc: 0.3343 - val_loss: 1.3558\n",
            "Epoch 83/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3253 - loss: 1.3568 - val_acc: 0.3466 - val_loss: 1.3488\n",
            "Epoch 84/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3323 - loss: 1.3532 - val_acc: 0.3395 - val_loss: 1.3500\n",
            "Epoch 85/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3358 - loss: 1.3494 - val_acc: 0.3447 - val_loss: 1.3500\n",
            "Epoch 86/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3342 - loss: 1.3521 - val_acc: 0.3361 - val_loss: 1.3494\n",
            "Epoch 87/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3352 - loss: 1.3494 - val_acc: 0.3404 - val_loss: 1.3477\n",
            "Epoch 88/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3338 - loss: 1.3525 - val_acc: 0.3384 - val_loss: 1.3479\n",
            "Epoch 89/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.3347 - loss: 1.3515 - val_acc: 0.3370 - val_loss: 1.3527\n",
            "Epoch 90/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3286 - loss: 1.3519 - val_acc: 0.3403 - val_loss: 1.3498\n",
            "Epoch 91/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3261 - loss: 1.3516 - val_acc: 0.3415 - val_loss: 1.3524\n",
            "Epoch 92/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3241 - loss: 1.3528 - val_acc: 0.3392 - val_loss: 1.3519\n",
            "Epoch 93/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3290 - loss: 1.3516 - val_acc: 0.3399 - val_loss: 1.3496\n",
            "Epoch 94/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3342 - loss: 1.3525 - val_acc: 0.3513 - val_loss: 1.3484\n",
            "Epoch 95/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3339 - loss: 1.3500 - val_acc: 0.3339 - val_loss: 1.3489\n",
            "Epoch 96/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3311 - loss: 1.3505 - val_acc: 0.3327 - val_loss: 1.3520\n",
            "Epoch 97/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3274 - loss: 1.3544 - val_acc: 0.3392 - val_loss: 1.3481\n",
            "Epoch 98/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3356 - loss: 1.3474 - val_acc: 0.3484 - val_loss: 1.3488\n",
            "Epoch 99/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.3292 - loss: 1.3515 - val_acc: 0.3455 - val_loss: 1.3516\n",
            "Epoch 100/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3330 - loss: 1.3503 - val_acc: 0.3526 - val_loss: 1.3467\n",
            "Epoch 101/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3348 - loss: 1.3481 - val_acc: 0.3433 - val_loss: 1.3494\n",
            "Epoch 102/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3310 - loss: 1.3504 - val_acc: 0.3412 - val_loss: 1.3501\n",
            "Epoch 103/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3328 - loss: 1.3486 - val_acc: 0.3412 - val_loss: 1.3493\n",
            "Epoch 104/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3285 - loss: 1.3480 - val_acc: 0.3427 - val_loss: 1.3495\n",
            "Epoch 105/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3341 - loss: 1.3478 - val_acc: 0.3415 - val_loss: 1.3488\n",
            "Epoch 106/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3318 - loss: 1.3510 - val_acc: 0.3406 - val_loss: 1.3518\n",
            "Epoch 107/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3250 - loss: 1.3485 - val_acc: 0.3461 - val_loss: 1.3492\n",
            "Epoch 108/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3295 - loss: 1.3489 - val_acc: 0.3378 - val_loss: 1.3532\n",
            "Epoch 109/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3274 - loss: 1.3497 - val_acc: 0.3395 - val_loss: 1.3568\n",
            "Epoch 110/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3410 - loss: 1.3461 - val_acc: 0.3429 - val_loss: 1.3501\n",
            "Epoch 111/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3376 - loss: 1.3455 - val_acc: 0.3419 - val_loss: 1.3523\n",
            "Epoch 112/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3385 - loss: 1.3467 - val_acc: 0.3475 - val_loss: 1.3493\n",
            "Epoch 113/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3314 - loss: 1.3443 - val_acc: 0.3447 - val_loss: 1.3505\n",
            "Epoch 114/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3306 - loss: 1.3488 - val_acc: 0.3406 - val_loss: 1.3512\n",
            "Epoch 115/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3267 - loss: 1.3475 - val_acc: 0.3435 - val_loss: 1.3515\n",
            "Epoch 116/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3347 - loss: 1.3433 - val_acc: 0.3293 - val_loss: 1.3521\n",
            "Epoch 117/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3330 - loss: 1.3437 - val_acc: 0.3335 - val_loss: 1.3525\n",
            "Epoch 118/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3344 - loss: 1.3441 - val_acc: 0.3395 - val_loss: 1.3512\n",
            "Epoch 119/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3379 - loss: 1.3450 - val_acc: 0.3338 - val_loss: 1.3535\n",
            "Epoch 120/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3318 - loss: 1.3498 - val_acc: 0.3412 - val_loss: 1.3514\n",
            "Epoch 121/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3273 - loss: 1.3453 - val_acc: 0.3421 - val_loss: 1.3501\n",
            "Epoch 122/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3362 - loss: 1.3421 - val_acc: 0.3444 - val_loss: 1.3498\n",
            "Epoch 123/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3332 - loss: 1.3456 - val_acc: 0.3452 - val_loss: 1.3495\n",
            "Epoch 124/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3385 - loss: 1.3441 - val_acc: 0.3370 - val_loss: 1.3500\n",
            "Epoch 125/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3357 - loss: 1.3427 - val_acc: 0.3446 - val_loss: 1.3501\n",
            "Epoch 126/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3364 - loss: 1.3442 - val_acc: 0.3442 - val_loss: 1.3514\n",
            "Epoch 127/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.3324 - loss: 1.3424 - val_acc: 0.3487 - val_loss: 1.3502\n",
            "Epoch 128/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3337 - loss: 1.3424 - val_acc: 0.3393 - val_loss: 1.3525\n",
            "Epoch 129/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3394 - loss: 1.3404 - val_acc: 0.3421 - val_loss: 1.3504\n",
            "Epoch 130/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3346 - loss: 1.3427 - val_acc: 0.3473 - val_loss: 1.3514\n",
            "Epoch 131/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3380 - loss: 1.3436 - val_acc: 0.3389 - val_loss: 1.3523\n",
            "Epoch 132/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3380 - loss: 1.3417 - val_acc: 0.3416 - val_loss: 1.3526\n",
            "Epoch 133/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3347 - loss: 1.3438 - val_acc: 0.3413 - val_loss: 1.3509\n",
            "Epoch 134/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3379 - loss: 1.3383 - val_acc: 0.3467 - val_loss: 1.3514\n",
            "Epoch 135/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3308 - loss: 1.3434 - val_acc: 0.3358 - val_loss: 1.3515\n",
            "Epoch 136/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3343 - loss: 1.3421 - val_acc: 0.3436 - val_loss: 1.3514\n",
            "Epoch 137/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3327 - loss: 1.3438 - val_acc: 0.3401 - val_loss: 1.3507\n",
            "Epoch 138/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3273 - loss: 1.3446 - val_acc: 0.3376 - val_loss: 1.3524\n",
            "Epoch 139/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3435 - loss: 1.3375 - val_acc: 0.3370 - val_loss: 1.3505\n",
            "Epoch 140/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3290 - loss: 1.3425 - val_acc: 0.3430 - val_loss: 1.3545\n",
            "Epoch 141/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3381 - loss: 1.3414 - val_acc: 0.3423 - val_loss: 1.3502\n",
            "Epoch 142/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3356 - loss: 1.3399 - val_acc: 0.3384 - val_loss: 1.3541\n",
            "Epoch 143/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3323 - loss: 1.3371 - val_acc: 0.3383 - val_loss: 1.3507\n",
            "Epoch 144/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3422 - loss: 1.3373 - val_acc: 0.3392 - val_loss: 1.3520\n",
            "Epoch 145/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3401 - loss: 1.3385 - val_acc: 0.3393 - val_loss: 1.3529\n",
            "Epoch 146/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3346 - loss: 1.3377 - val_acc: 0.3367 - val_loss: 1.3503\n",
            "Epoch 147/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3363 - loss: 1.3422 - val_acc: 0.3452 - val_loss: 1.3507\n",
            "Epoch 148/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3375 - loss: 1.3379 - val_acc: 0.3469 - val_loss: 1.3515\n",
            "Epoch 149/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3402 - loss: 1.3364 - val_acc: 0.3399 - val_loss: 1.3512\n",
            "Epoch 150/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3387 - loss: 1.3400 - val_acc: 0.3418 - val_loss: 1.3509\n",
            "Epoch 151/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3359 - loss: 1.3395 - val_acc: 0.3439 - val_loss: 1.3538\n",
            "Epoch 152/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3318 - loss: 1.3384 - val_acc: 0.3398 - val_loss: 1.3507\n",
            "Epoch 153/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3348 - loss: 1.3383 - val_acc: 0.3495 - val_loss: 1.3496\n",
            "Epoch 154/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3358 - loss: 1.3393 - val_acc: 0.3392 - val_loss: 1.3507\n",
            "Epoch 155/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3333 - loss: 1.3388 - val_acc: 0.3442 - val_loss: 1.3494\n",
            "Epoch 156/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3356 - loss: 1.3375 - val_acc: 0.3436 - val_loss: 1.3510\n",
            "Epoch 157/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3378 - loss: 1.3361 - val_acc: 0.3387 - val_loss: 1.3521\n",
            "Epoch 158/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3364 - loss: 1.3365 - val_acc: 0.3430 - val_loss: 1.3512\n",
            "Epoch 159/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3277 - loss: 1.3408 - val_acc: 0.3386 - val_loss: 1.3509\n",
            "Epoch 160/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3383 - loss: 1.3356 - val_acc: 0.3393 - val_loss: 1.3506\n",
            "Epoch 161/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3373 - loss: 1.3368 - val_acc: 0.3386 - val_loss: 1.3505\n",
            "Epoch 162/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3390 - loss: 1.3356 - val_acc: 0.3444 - val_loss: 1.3521\n",
            "Epoch 163/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3348 - loss: 1.3348 - val_acc: 0.3439 - val_loss: 1.3512\n",
            "Epoch 164/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3306 - loss: 1.3381 - val_acc: 0.3419 - val_loss: 1.3504\n",
            "Epoch 165/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3332 - loss: 1.3358 - val_acc: 0.3393 - val_loss: 1.3501\n",
            "Epoch 166/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3369 - loss: 1.3355 - val_acc: 0.3406 - val_loss: 1.3498\n",
            "Epoch 167/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3349 - loss: 1.3355 - val_acc: 0.3390 - val_loss: 1.3504\n",
            "Epoch 168/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3396 - loss: 1.3371 - val_acc: 0.3395 - val_loss: 1.3505\n",
            "Epoch 169/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3394 - loss: 1.3330 - val_acc: 0.3409 - val_loss: 1.3504\n",
            "Epoch 170/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3432 - loss: 1.3309 - val_acc: 0.3415 - val_loss: 1.3514\n",
            "Epoch 171/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3379 - loss: 1.3347 - val_acc: 0.3352 - val_loss: 1.3519\n",
            "Epoch 172/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3369 - loss: 1.3306 - val_acc: 0.3329 - val_loss: 1.3515\n",
            "Epoch 173/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3359 - loss: 1.3334 - val_acc: 0.3390 - val_loss: 1.3528\n",
            "Epoch 174/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3356 - loss: 1.3355 - val_acc: 0.3439 - val_loss: 1.3507\n",
            "Epoch 175/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3377 - loss: 1.3330 - val_acc: 0.3407 - val_loss: 1.3533\n",
            "Epoch 176/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3359 - loss: 1.3327 - val_acc: 0.3323 - val_loss: 1.3548\n",
            "Epoch 177/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3366 - loss: 1.3325 - val_acc: 0.3430 - val_loss: 1.3539\n",
            "Epoch 178/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3253 - loss: 1.3385 - val_acc: 0.3409 - val_loss: 1.3511\n",
            "Epoch 179/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3339 - loss: 1.3343 - val_acc: 0.3473 - val_loss: 1.3515\n",
            "Epoch 180/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3354 - loss: 1.3331 - val_acc: 0.3353 - val_loss: 1.3533\n",
            "Epoch 181/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3421 - loss: 1.3298 - val_acc: 0.3456 - val_loss: 1.3524\n",
            "Epoch 182/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3318 - loss: 1.3374 - val_acc: 0.3441 - val_loss: 1.3513\n",
            "Epoch 183/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3396 - loss: 1.3311 - val_acc: 0.3310 - val_loss: 1.3511\n",
            "Epoch 184/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3384 - loss: 1.3273 - val_acc: 0.3358 - val_loss: 1.3579\n",
            "Epoch 185/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3386 - loss: 1.3297 - val_acc: 0.3375 - val_loss: 1.3511\n",
            "Epoch 186/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3349 - loss: 1.3318 - val_acc: 0.3292 - val_loss: 1.3507\n",
            "Epoch 187/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3360 - loss: 1.3341 - val_acc: 0.3393 - val_loss: 1.3512\n",
            "Epoch 188/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3339 - loss: 1.3339 - val_acc: 0.3303 - val_loss: 1.3508\n",
            "Epoch 189/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3394 - loss: 1.3291 - val_acc: 0.3350 - val_loss: 1.3514\n",
            "Epoch 190/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3329 - loss: 1.3339 - val_acc: 0.3379 - val_loss: 1.3599\n",
            "Epoch 191/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3343 - loss: 1.3327 - val_acc: 0.3381 - val_loss: 1.3529\n",
            "Epoch 192/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3361 - loss: 1.3349 - val_acc: 0.3378 - val_loss: 1.3533\n",
            "Epoch 193/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3344 - loss: 1.3327 - val_acc: 0.3316 - val_loss: 1.3533\n",
            "Epoch 194/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3377 - loss: 1.3315 - val_acc: 0.3319 - val_loss: 1.3543\n",
            "Epoch 195/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3341 - loss: 1.3295 - val_acc: 0.3372 - val_loss: 1.3523\n",
            "Epoch 196/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3431 - loss: 1.3309 - val_acc: 0.3283 - val_loss: 1.3539\n",
            "Epoch 197/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3407 - loss: 1.3275 - val_acc: 0.3384 - val_loss: 1.3500\n",
            "Epoch 198/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3326 - loss: 1.3334 - val_acc: 0.3361 - val_loss: 1.3515\n",
            "Epoch 199/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3416 - loss: 1.3253 - val_acc: 0.3406 - val_loss: 1.3500\n",
            "Epoch 200/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3412 - loss: 1.3303 - val_acc: 0.3326 - val_loss: 1.3538\n",
            "Epoch 201/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3425 - loss: 1.3284 - val_acc: 0.3353 - val_loss: 1.3513\n",
            "Epoch 202/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3387 - loss: 1.3301 - val_acc: 0.3409 - val_loss: 1.3495\n",
            "Epoch 203/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3452 - loss: 1.3263 - val_acc: 0.3319 - val_loss: 1.3499\n",
            "Epoch 204/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3453 - loss: 1.3284 - val_acc: 0.3212 - val_loss: 1.3507\n",
            "Epoch 205/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3398 - loss: 1.3284 - val_acc: 0.3366 - val_loss: 1.3529\n",
            "Epoch 206/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3315 - loss: 1.3281 - val_acc: 0.3336 - val_loss: 1.3522\n",
            "Epoch 207/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3390 - loss: 1.3287 - val_acc: 0.3352 - val_loss: 1.3538\n",
            "Epoch 208/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3432 - loss: 1.3240 - val_acc: 0.3218 - val_loss: 1.3509\n",
            "Epoch 209/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3339 - loss: 1.3303 - val_acc: 0.3319 - val_loss: 1.3495\n",
            "Epoch 210/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3410 - loss: 1.3294 - val_acc: 0.3355 - val_loss: 1.3527\n",
            "Epoch 211/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3443 - loss: 1.3200 - val_acc: 0.3332 - val_loss: 1.3510\n",
            "Epoch 212/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3370 - loss: 1.3247 - val_acc: 0.3338 - val_loss: 1.3517\n",
            "Epoch 213/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3368 - loss: 1.3300 - val_acc: 0.3323 - val_loss: 1.3526\n",
            "Epoch 214/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3450 - loss: 1.3270 - val_acc: 0.3315 - val_loss: 1.3509\n",
            "Epoch 215/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3463 - loss: 1.3233 - val_acc: 0.3276 - val_loss: 1.3513\n",
            "Epoch 216/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3373 - loss: 1.3238 - val_acc: 0.3318 - val_loss: 1.3500\n",
            "Epoch 217/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3413 - loss: 1.3270 - val_acc: 0.3306 - val_loss: 1.3543\n",
            "Epoch 218/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3377 - loss: 1.3240 - val_acc: 0.3316 - val_loss: 1.3527\n",
            "Epoch 219/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3442 - loss: 1.3249 - val_acc: 0.3329 - val_loss: 1.3533\n",
            "Epoch 220/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3329 - loss: 1.3272 - val_acc: 0.3379 - val_loss: 1.3470\n",
            "Epoch 221/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3387 - loss: 1.3279 - val_acc: 0.3356 - val_loss: 1.3505\n",
            "Epoch 222/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3368 - loss: 1.3293 - val_acc: 0.3333 - val_loss: 1.3490\n",
            "Epoch 223/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3360 - loss: 1.3279 - val_acc: 0.3333 - val_loss: 1.3501\n",
            "Epoch 224/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3438 - loss: 1.3254 - val_acc: 0.3267 - val_loss: 1.3480\n",
            "Epoch 225/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3406 - loss: 1.3243 - val_acc: 0.3246 - val_loss: 1.3493\n",
            "Epoch 226/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3420 - loss: 1.3280 - val_acc: 0.3375 - val_loss: 1.3548\n",
            "Epoch 227/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3326 - loss: 1.3285 - val_acc: 0.3306 - val_loss: 1.3474\n",
            "Epoch 228/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3400 - loss: 1.3231 - val_acc: 0.3366 - val_loss: 1.3489\n",
            "Epoch 229/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3429 - loss: 1.3223 - val_acc: 0.3327 - val_loss: 1.3516\n",
            "Epoch 230/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3490 - loss: 1.3181 - val_acc: 0.3333 - val_loss: 1.3526\n",
            "Epoch 231/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3386 - loss: 1.3229 - val_acc: 0.3315 - val_loss: 1.3495\n",
            "Epoch 232/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3385 - loss: 1.3243 - val_acc: 0.3286 - val_loss: 1.3525\n",
            "Epoch 233/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3399 - loss: 1.3240 - val_acc: 0.3252 - val_loss: 1.3515\n",
            "Epoch 234/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3423 - loss: 1.3200 - val_acc: 0.3383 - val_loss: 1.3485\n",
            "Epoch 235/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3406 - loss: 1.3217 - val_acc: 0.3339 - val_loss: 1.3541\n",
            "Epoch 236/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3401 - loss: 1.3196 - val_acc: 0.3329 - val_loss: 1.3511\n",
            "Epoch 237/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3434 - loss: 1.3206 - val_acc: 0.3238 - val_loss: 1.3502\n",
            "Epoch 238/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3425 - loss: 1.3214 - val_acc: 0.3396 - val_loss: 1.3510\n",
            "Epoch 239/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3433 - loss: 1.3268 - val_acc: 0.3386 - val_loss: 1.3534\n",
            "Epoch 240/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3394 - loss: 1.3216 - val_acc: 0.3236 - val_loss: 1.3502\n",
            "Epoch 241/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3416 - loss: 1.3244 - val_acc: 0.3287 - val_loss: 1.3505\n",
            "Epoch 242/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3514 - loss: 1.3190 - val_acc: 0.3310 - val_loss: 1.3524\n",
            "Epoch 243/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3409 - loss: 1.3226 - val_acc: 0.3300 - val_loss: 1.3486\n",
            "Epoch 244/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3384 - loss: 1.3212 - val_acc: 0.3235 - val_loss: 1.3492\n",
            "Epoch 245/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3388 - loss: 1.3220 - val_acc: 0.3373 - val_loss: 1.3490\n",
            "Epoch 246/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3426 - loss: 1.3207 - val_acc: 0.3224 - val_loss: 1.3525\n",
            "Epoch 247/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3399 - loss: 1.3221 - val_acc: 0.3283 - val_loss: 1.3480\n",
            "Epoch 248/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3396 - loss: 1.3252 - val_acc: 0.3209 - val_loss: 1.3488\n",
            "Epoch 249/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3426 - loss: 1.3237 - val_acc: 0.3269 - val_loss: 1.3504\n",
            "Epoch 250/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3455 - loss: 1.3189 - val_acc: 0.3241 - val_loss: 1.3501\n",
            "Epoch 251/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3462 - loss: 1.3169 - val_acc: 0.3292 - val_loss: 1.3514\n",
            "Epoch 252/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3401 - loss: 1.3188 - val_acc: 0.3335 - val_loss: 1.3573\n",
            "Epoch 253/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3417 - loss: 1.3215 - val_acc: 0.3312 - val_loss: 1.3517\n",
            "Epoch 254/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.3504 - loss: 1.3184 - val_acc: 0.3313 - val_loss: 1.3531\n",
            "Epoch 255/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - acc: 0.3443 - loss: 1.3216 - val_acc: 0.3255 - val_loss: 1.3588\n",
            "Epoch 256/256\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3351 - loss: 1.3278 - val_acc: 0.3330 - val_loss: 1.3499\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 628ms/step\n",
            "Epoch 1/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 127ms/step - acc: 0.2523 - loss: 1.3895 - val_acc: 0.2500 - val_loss: 1.3861\n",
            "Epoch 2/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.2630 - loss: 1.3857 - val_acc: 0.3237 - val_loss: 1.3660\n",
            "Epoch 3/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3342 - loss: 1.3547 - val_acc: 0.4262 - val_loss: 1.2920\n",
            "Epoch 4/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.3948 - loss: 1.2976 - val_acc: 0.4526 - val_loss: 1.2427\n",
            "Epoch 5/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4230 - loss: 1.2645 - val_acc: 0.4716 - val_loss: 1.2210\n",
            "Epoch 6/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4373 - loss: 1.2512 - val_acc: 0.4715 - val_loss: 1.2164\n",
            "Epoch 7/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4432 - loss: 1.2421 - val_acc: 0.4658 - val_loss: 1.2119\n",
            "Epoch 8/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4440 - loss: 1.2390 - val_acc: 0.4740 - val_loss: 1.2046\n",
            "Epoch 9/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4513 - loss: 1.2330 - val_acc: 0.4732 - val_loss: 1.2091\n",
            "Epoch 10/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4526 - loss: 1.2283 - val_acc: 0.4732 - val_loss: 1.2078\n",
            "Epoch 11/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4562 - loss: 1.2295 - val_acc: 0.4695 - val_loss: 1.2008\n",
            "Epoch 12/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4564 - loss: 1.2253 - val_acc: 0.4788 - val_loss: 1.1981\n",
            "Epoch 13/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4569 - loss: 1.2208 - val_acc: 0.4757 - val_loss: 1.1984\n",
            "Epoch 14/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4560 - loss: 1.2212 - val_acc: 0.4718 - val_loss: 1.1980\n",
            "Epoch 15/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4605 - loss: 1.2193 - val_acc: 0.4848 - val_loss: 1.1941\n",
            "Epoch 16/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4605 - loss: 1.2168 - val_acc: 0.4771 - val_loss: 1.1965\n",
            "Epoch 17/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4620 - loss: 1.2163 - val_acc: 0.4798 - val_loss: 1.1940\n",
            "Epoch 18/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4630 - loss: 1.2159 - val_acc: 0.4782 - val_loss: 1.1903\n",
            "Epoch 19/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4610 - loss: 1.2155 - val_acc: 0.4733 - val_loss: 1.2053\n",
            "Epoch 20/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4628 - loss: 1.2182 - val_acc: 0.4740 - val_loss: 1.1943\n",
            "Epoch 21/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4617 - loss: 1.2181 - val_acc: 0.4840 - val_loss: 1.1935\n",
            "Epoch 22/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4650 - loss: 1.2155 - val_acc: 0.4778 - val_loss: 1.1915\n",
            "Epoch 23/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4621 - loss: 1.2125 - val_acc: 0.4813 - val_loss: 1.1931\n",
            "Epoch 24/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4644 - loss: 1.2130 - val_acc: 0.4714 - val_loss: 1.1998\n",
            "Epoch 25/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4660 - loss: 1.2146 - val_acc: 0.4748 - val_loss: 1.1924\n",
            "Epoch 26/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4632 - loss: 1.2141 - val_acc: 0.4759 - val_loss: 1.1968\n",
            "Epoch 27/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4678 - loss: 1.2109 - val_acc: 0.4811 - val_loss: 1.1901\n",
            "Epoch 28/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4634 - loss: 1.2128 - val_acc: 0.4782 - val_loss: 1.1912\n",
            "Epoch 29/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4694 - loss: 1.2048 - val_acc: 0.4824 - val_loss: 1.1945\n",
            "Epoch 30/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4673 - loss: 1.2114 - val_acc: 0.4738 - val_loss: 1.1978\n",
            "Epoch 31/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4646 - loss: 1.2141 - val_acc: 0.4749 - val_loss: 1.1899\n",
            "Epoch 32/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4661 - loss: 1.2112 - val_acc: 0.4739 - val_loss: 1.1912\n",
            "Epoch 33/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4616 - loss: 1.2124 - val_acc: 0.4784 - val_loss: 1.1902\n",
            "Epoch 34/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4690 - loss: 1.2102 - val_acc: 0.4766 - val_loss: 1.1914\n",
            "Epoch 35/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4621 - loss: 1.2136 - val_acc: 0.4795 - val_loss: 1.1945\n",
            "Epoch 36/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4680 - loss: 1.2081 - val_acc: 0.4804 - val_loss: 1.1886\n",
            "Epoch 37/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4714 - loss: 1.2048 - val_acc: 0.4739 - val_loss: 1.1953\n",
            "Epoch 38/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4651 - loss: 1.2102 - val_acc: 0.4790 - val_loss: 1.1882\n",
            "Epoch 39/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4690 - loss: 1.2077 - val_acc: 0.4716 - val_loss: 1.1965\n",
            "Epoch 40/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4676 - loss: 1.2094 - val_acc: 0.4781 - val_loss: 1.1957\n",
            "Epoch 41/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4704 - loss: 1.2016 - val_acc: 0.4701 - val_loss: 1.1996\n",
            "Epoch 42/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4669 - loss: 1.2112 - val_acc: 0.4829 - val_loss: 1.1897\n",
            "Epoch 43/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4675 - loss: 1.2082 - val_acc: 0.4789 - val_loss: 1.1927\n",
            "Epoch 44/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4687 - loss: 1.2061 - val_acc: 0.4863 - val_loss: 1.1879\n",
            "Epoch 45/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4668 - loss: 1.2066 - val_acc: 0.4834 - val_loss: 1.1931\n",
            "Epoch 46/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4686 - loss: 1.2059 - val_acc: 0.4768 - val_loss: 1.1950\n",
            "Epoch 47/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4659 - loss: 1.2066 - val_acc: 0.4826 - val_loss: 1.1908\n",
            "Epoch 48/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4673 - loss: 1.2109 - val_acc: 0.4764 - val_loss: 1.1933\n",
            "Epoch 49/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4671 - loss: 1.2090 - val_acc: 0.4724 - val_loss: 1.1934\n",
            "Epoch 50/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4677 - loss: 1.2085 - val_acc: 0.4819 - val_loss: 1.1900\n",
            "Epoch 51/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4689 - loss: 1.2000 - val_acc: 0.4760 - val_loss: 1.1930\n",
            "Epoch 52/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4669 - loss: 1.2060 - val_acc: 0.4793 - val_loss: 1.1876\n",
            "Epoch 53/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4695 - loss: 1.2041 - val_acc: 0.4781 - val_loss: 1.1894\n",
            "Epoch 54/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4713 - loss: 1.2012 - val_acc: 0.4731 - val_loss: 1.1984\n",
            "Epoch 55/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4713 - loss: 1.2076 - val_acc: 0.4767 - val_loss: 1.1915\n",
            "Epoch 56/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4702 - loss: 1.2045 - val_acc: 0.4738 - val_loss: 1.1941\n",
            "Epoch 57/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4652 - loss: 1.2107 - val_acc: 0.4798 - val_loss: 1.1887\n",
            "Epoch 58/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4702 - loss: 1.2037 - val_acc: 0.4732 - val_loss: 1.1918\n",
            "Epoch 59/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4721 - loss: 1.1993 - val_acc: 0.4807 - val_loss: 1.1900\n",
            "Epoch 60/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4706 - loss: 1.2040 - val_acc: 0.4790 - val_loss: 1.1927\n",
            "Epoch 61/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4725 - loss: 1.2011 - val_acc: 0.4768 - val_loss: 1.1882\n",
            "Epoch 62/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4707 - loss: 1.2018 - val_acc: 0.4771 - val_loss: 1.1898\n",
            "Epoch 63/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4717 - loss: 1.1998 - val_acc: 0.4773 - val_loss: 1.1933\n",
            "Epoch 64/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4756 - loss: 1.1984 - val_acc: 0.4789 - val_loss: 1.1915\n",
            "Epoch 65/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4732 - loss: 1.2021 - val_acc: 0.4767 - val_loss: 1.1939\n",
            "Epoch 66/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4741 - loss: 1.1996 - val_acc: 0.4770 - val_loss: 1.1941\n",
            "Epoch 67/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4705 - loss: 1.2009 - val_acc: 0.4721 - val_loss: 1.2014\n",
            "Epoch 68/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4758 - loss: 1.1994 - val_acc: 0.4708 - val_loss: 1.1976\n",
            "Epoch 69/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4692 - loss: 1.2060 - val_acc: 0.4726 - val_loss: 1.1979\n",
            "Epoch 70/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4731 - loss: 1.1989 - val_acc: 0.4796 - val_loss: 1.1936\n",
            "Epoch 71/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4699 - loss: 1.2031 - val_acc: 0.4748 - val_loss: 1.1966\n",
            "Epoch 72/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4791 - loss: 1.1979 - val_acc: 0.4816 - val_loss: 1.1905\n",
            "Epoch 73/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4747 - loss: 1.2024 - val_acc: 0.4782 - val_loss: 1.1937\n",
            "Epoch 74/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4735 - loss: 1.1962 - val_acc: 0.4756 - val_loss: 1.1960\n",
            "Epoch 75/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4688 - loss: 1.2030 - val_acc: 0.4707 - val_loss: 1.1984\n",
            "Epoch 76/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4688 - loss: 1.2002 - val_acc: 0.4748 - val_loss: 1.1916\n",
            "Epoch 77/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4729 - loss: 1.2002 - val_acc: 0.4764 - val_loss: 1.2010\n",
            "Epoch 78/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4715 - loss: 1.2027 - val_acc: 0.4829 - val_loss: 1.1883\n",
            "Epoch 79/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4772 - loss: 1.1937 - val_acc: 0.4787 - val_loss: 1.1934\n",
            "Epoch 80/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4729 - loss: 1.1987 - val_acc: 0.4811 - val_loss: 1.1897\n",
            "Epoch 81/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4749 - loss: 1.1978 - val_acc: 0.4772 - val_loss: 1.1959\n",
            "Epoch 82/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4773 - loss: 1.1931 - val_acc: 0.4766 - val_loss: 1.1959\n",
            "Epoch 83/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4755 - loss: 1.1935 - val_acc: 0.4749 - val_loss: 1.1983\n",
            "Epoch 84/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4744 - loss: 1.1945 - val_acc: 0.4862 - val_loss: 1.1923\n",
            "Epoch 85/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4753 - loss: 1.1937 - val_acc: 0.4811 - val_loss: 1.1971\n",
            "Epoch 86/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4750 - loss: 1.2005 - val_acc: 0.4810 - val_loss: 1.1929\n",
            "Epoch 87/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4759 - loss: 1.1962 - val_acc: 0.4762 - val_loss: 1.1945\n",
            "Epoch 88/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4700 - loss: 1.1992 - val_acc: 0.4848 - val_loss: 1.1935\n",
            "Epoch 89/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4731 - loss: 1.1995 - val_acc: 0.4803 - val_loss: 1.1933\n",
            "Epoch 90/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4714 - loss: 1.1947 - val_acc: 0.4785 - val_loss: 1.1963\n",
            "Epoch 91/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4754 - loss: 1.1918 - val_acc: 0.4737 - val_loss: 1.1984\n",
            "Epoch 92/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4813 - loss: 1.1891 - val_acc: 0.4803 - val_loss: 1.1980\n",
            "Epoch 93/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4742 - loss: 1.1984 - val_acc: 0.4848 - val_loss: 1.1946\n",
            "Epoch 94/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4746 - loss: 1.1957 - val_acc: 0.4734 - val_loss: 1.1969\n",
            "Epoch 95/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4764 - loss: 1.1942 - val_acc: 0.4799 - val_loss: 1.1926\n",
            "Epoch 96/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4780 - loss: 1.1914 - val_acc: 0.4750 - val_loss: 1.1977\n",
            "Epoch 97/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4723 - loss: 1.1976 - val_acc: 0.4762 - val_loss: 1.1983\n",
            "Epoch 98/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4769 - loss: 1.1944 - val_acc: 0.4798 - val_loss: 1.1960\n",
            "Epoch 99/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4689 - loss: 1.1991 - val_acc: 0.4798 - val_loss: 1.1935\n",
            "Epoch 100/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4802 - loss: 1.1876 - val_acc: 0.4797 - val_loss: 1.1992\n",
            "Epoch 101/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4791 - loss: 1.1904 - val_acc: 0.4795 - val_loss: 1.1973\n",
            "Epoch 102/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4749 - loss: 1.1977 - val_acc: 0.4760 - val_loss: 1.1971\n",
            "Epoch 103/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4812 - loss: 1.1905 - val_acc: 0.4795 - val_loss: 1.1968\n",
            "Epoch 104/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4732 - loss: 1.1984 - val_acc: 0.4796 - val_loss: 1.1954\n",
            "Epoch 105/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4738 - loss: 1.1958 - val_acc: 0.4814 - val_loss: 1.1971\n",
            "Epoch 106/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4756 - loss: 1.1929 - val_acc: 0.4787 - val_loss: 1.1959\n",
            "Epoch 107/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4738 - loss: 1.1982 - val_acc: 0.4794 - val_loss: 1.1955\n",
            "Epoch 108/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4779 - loss: 1.1910 - val_acc: 0.4809 - val_loss: 1.1981\n",
            "Epoch 109/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4778 - loss: 1.1905 - val_acc: 0.4832 - val_loss: 1.2015\n",
            "Epoch 110/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4734 - loss: 1.1961 - val_acc: 0.4730 - val_loss: 1.2010\n",
            "Epoch 111/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4764 - loss: 1.1940 - val_acc: 0.4645 - val_loss: 1.2070\n",
            "Epoch 112/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4813 - loss: 1.1887 - val_acc: 0.4793 - val_loss: 1.1999\n",
            "Epoch 113/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4751 - loss: 1.1928 - val_acc: 0.4764 - val_loss: 1.1984\n",
            "Epoch 114/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4780 - loss: 1.1944 - val_acc: 0.4773 - val_loss: 1.1978\n",
            "Epoch 115/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4773 - loss: 1.1925 - val_acc: 0.4803 - val_loss: 1.1971\n",
            "Epoch 116/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4755 - loss: 1.1976 - val_acc: 0.4746 - val_loss: 1.1978\n",
            "Epoch 117/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4787 - loss: 1.1911 - val_acc: 0.4775 - val_loss: 1.2010\n",
            "Epoch 118/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4766 - loss: 1.1948 - val_acc: 0.4765 - val_loss: 1.1984\n",
            "Epoch 119/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4765 - loss: 1.1961 - val_acc: 0.4784 - val_loss: 1.1932\n",
            "Epoch 120/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4799 - loss: 1.1914 - val_acc: 0.4799 - val_loss: 1.1985\n",
            "Epoch 121/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4776 - loss: 1.1914 - val_acc: 0.4832 - val_loss: 1.1963\n",
            "Epoch 122/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4782 - loss: 1.1921 - val_acc: 0.4818 - val_loss: 1.1959\n",
            "Epoch 123/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4759 - loss: 1.1902 - val_acc: 0.4815 - val_loss: 1.1979\n",
            "Epoch 124/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4773 - loss: 1.1915 - val_acc: 0.4755 - val_loss: 1.1958\n",
            "Epoch 125/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4808 - loss: 1.1893 - val_acc: 0.4798 - val_loss: 1.2039\n",
            "Epoch 126/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4773 - loss: 1.1909 - val_acc: 0.4778 - val_loss: 1.1978\n",
            "Epoch 127/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4760 - loss: 1.1931 - val_acc: 0.4788 - val_loss: 1.1973\n",
            "Epoch 128/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4768 - loss: 1.1919 - val_acc: 0.4836 - val_loss: 1.1974\n",
            "Epoch 129/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4777 - loss: 1.1913 - val_acc: 0.4785 - val_loss: 1.1999\n",
            "Epoch 130/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4797 - loss: 1.1880 - val_acc: 0.4736 - val_loss: 1.2011\n",
            "Epoch 131/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4755 - loss: 1.1922 - val_acc: 0.4767 - val_loss: 1.2027\n",
            "Epoch 132/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4813 - loss: 1.1902 - val_acc: 0.4803 - val_loss: 1.2001\n",
            "Epoch 133/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4760 - loss: 1.1894 - val_acc: 0.4757 - val_loss: 1.1999\n",
            "Epoch 134/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4797 - loss: 1.1892 - val_acc: 0.4790 - val_loss: 1.2024\n",
            "Epoch 135/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4784 - loss: 1.1893 - val_acc: 0.4742 - val_loss: 1.2012\n",
            "Epoch 136/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4769 - loss: 1.1893 - val_acc: 0.4823 - val_loss: 1.2016\n",
            "Epoch 137/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4802 - loss: 1.1879 - val_acc: 0.4820 - val_loss: 1.1983\n",
            "Epoch 138/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4768 - loss: 1.1889 - val_acc: 0.4782 - val_loss: 1.2068\n",
            "Epoch 139/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4750 - loss: 1.1936 - val_acc: 0.4782 - val_loss: 1.2009\n",
            "Epoch 140/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4776 - loss: 1.1905 - val_acc: 0.4720 - val_loss: 1.2043\n",
            "Epoch 141/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4816 - loss: 1.1867 - val_acc: 0.4773 - val_loss: 1.2027\n",
            "Epoch 142/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4734 - loss: 1.1899 - val_acc: 0.4807 - val_loss: 1.2020\n",
            "Epoch 143/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4771 - loss: 1.1874 - val_acc: 0.4712 - val_loss: 1.2022\n",
            "Epoch 144/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4775 - loss: 1.1873 - val_acc: 0.4748 - val_loss: 1.2090\n",
            "Epoch 145/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4791 - loss: 1.1881 - val_acc: 0.4780 - val_loss: 1.2000\n",
            "Epoch 146/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4786 - loss: 1.1873 - val_acc: 0.4793 - val_loss: 1.1989\n",
            "Epoch 147/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4799 - loss: 1.1873 - val_acc: 0.4790 - val_loss: 1.2011\n",
            "Epoch 148/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4793 - loss: 1.1900 - val_acc: 0.4812 - val_loss: 1.1995\n",
            "Epoch 149/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4783 - loss: 1.1912 - val_acc: 0.4799 - val_loss: 1.2025\n",
            "Epoch 150/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4767 - loss: 1.1924 - val_acc: 0.4744 - val_loss: 1.2057\n",
            "Epoch 151/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4764 - loss: 1.1908 - val_acc: 0.4746 - val_loss: 1.1992\n",
            "Epoch 152/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4768 - loss: 1.1868 - val_acc: 0.4793 - val_loss: 1.2017\n",
            "Epoch 153/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4792 - loss: 1.1883 - val_acc: 0.4813 - val_loss: 1.1976\n",
            "Epoch 154/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4819 - loss: 1.1876 - val_acc: 0.4763 - val_loss: 1.2030\n",
            "Epoch 155/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4756 - loss: 1.1894 - val_acc: 0.4799 - val_loss: 1.2004\n",
            "Epoch 156/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4740 - loss: 1.1914 - val_acc: 0.4771 - val_loss: 1.2005\n",
            "Epoch 157/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4789 - loss: 1.1890 - val_acc: 0.4832 - val_loss: 1.2035\n",
            "Epoch 158/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4802 - loss: 1.1895 - val_acc: 0.4818 - val_loss: 1.1993\n",
            "Epoch 159/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4840 - loss: 1.1816 - val_acc: 0.4787 - val_loss: 1.1986\n",
            "Epoch 160/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4755 - loss: 1.1844 - val_acc: 0.4803 - val_loss: 1.1998\n",
            "Epoch 161/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4822 - loss: 1.1844 - val_acc: 0.4757 - val_loss: 1.2036\n",
            "Epoch 162/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - acc: 0.4782 - loss: 1.1912 - val_acc: 0.4795 - val_loss: 1.1978\n",
            "Epoch 163/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - acc: 0.4811 - loss: 1.1874 - val_acc: 0.4782 - val_loss: 1.2009\n",
            "Epoch 164/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4791 - loss: 1.1901 - val_acc: 0.4778 - val_loss: 1.2021\n",
            "Epoch 165/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4784 - loss: 1.1891 - val_acc: 0.4792 - val_loss: 1.2031\n",
            "Epoch 166/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4811 - loss: 1.1837 - val_acc: 0.4843 - val_loss: 1.2018\n",
            "Epoch 167/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4773 - loss: 1.1864 - val_acc: 0.4822 - val_loss: 1.2041\n",
            "Epoch 168/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4823 - loss: 1.1872 - val_acc: 0.4788 - val_loss: 1.2002\n",
            "Epoch 169/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4759 - loss: 1.1903 - val_acc: 0.4811 - val_loss: 1.2017\n",
            "Epoch 170/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4775 - loss: 1.1902 - val_acc: 0.4753 - val_loss: 1.1997\n",
            "Epoch 171/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4773 - loss: 1.1877 - val_acc: 0.4818 - val_loss: 1.2010\n",
            "Epoch 172/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4791 - loss: 1.1865 - val_acc: 0.4754 - val_loss: 1.2017\n",
            "Epoch 173/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4784 - loss: 1.1908 - val_acc: 0.4778 - val_loss: 1.2002\n",
            "Epoch 174/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4800 - loss: 1.1871 - val_acc: 0.4832 - val_loss: 1.2009\n",
            "Epoch 175/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4821 - loss: 1.1860 - val_acc: 0.4818 - val_loss: 1.2025\n",
            "Epoch 176/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4788 - loss: 1.1897 - val_acc: 0.4793 - val_loss: 1.1997\n",
            "Epoch 177/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4783 - loss: 1.1866 - val_acc: 0.4832 - val_loss: 1.2004\n",
            "Epoch 178/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4828 - loss: 1.1874 - val_acc: 0.4781 - val_loss: 1.2016\n",
            "Epoch 179/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4766 - loss: 1.1860 - val_acc: 0.4780 - val_loss: 1.2030\n",
            "Epoch 180/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4788 - loss: 1.1884 - val_acc: 0.4820 - val_loss: 1.2030\n",
            "Epoch 181/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4781 - loss: 1.1895 - val_acc: 0.4768 - val_loss: 1.2002\n",
            "Epoch 182/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4769 - loss: 1.1890 - val_acc: 0.4764 - val_loss: 1.1998\n",
            "Epoch 183/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4767 - loss: 1.1883 - val_acc: 0.4824 - val_loss: 1.2015\n",
            "Epoch 184/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4772 - loss: 1.1893 - val_acc: 0.4802 - val_loss: 1.2043\n",
            "Epoch 185/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4787 - loss: 1.1855 - val_acc: 0.4764 - val_loss: 1.2068\n",
            "Epoch 186/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4771 - loss: 1.1894 - val_acc: 0.4782 - val_loss: 1.2008\n",
            "Epoch 187/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4813 - loss: 1.1865 - val_acc: 0.4771 - val_loss: 1.2024\n",
            "Epoch 188/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4767 - loss: 1.1918 - val_acc: 0.4782 - val_loss: 1.2065\n",
            "Epoch 189/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4725 - loss: 1.1924 - val_acc: 0.4799 - val_loss: 1.2024\n",
            "Epoch 190/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4764 - loss: 1.1875 - val_acc: 0.4781 - val_loss: 1.2023\n",
            "Epoch 191/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4789 - loss: 1.1857 - val_acc: 0.4817 - val_loss: 1.2035\n",
            "Epoch 192/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4798 - loss: 1.1879 - val_acc: 0.4785 - val_loss: 1.2054\n",
            "Epoch 193/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4764 - loss: 1.1894 - val_acc: 0.4725 - val_loss: 1.2077\n",
            "Epoch 194/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4827 - loss: 1.1821 - val_acc: 0.4767 - val_loss: 1.2034\n",
            "Epoch 195/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4790 - loss: 1.1900 - val_acc: 0.4702 - val_loss: 1.2006\n",
            "Epoch 196/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4726 - loss: 1.1916 - val_acc: 0.4795 - val_loss: 1.2021\n",
            "Epoch 197/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4786 - loss: 1.1861 - val_acc: 0.4842 - val_loss: 1.2055\n",
            "Epoch 198/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4803 - loss: 1.1857 - val_acc: 0.4776 - val_loss: 1.2026\n",
            "Epoch 199/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4802 - loss: 1.1868 - val_acc: 0.4810 - val_loss: 1.2056\n",
            "Epoch 200/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4761 - loss: 1.1910 - val_acc: 0.4749 - val_loss: 1.2050\n",
            "Epoch 201/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4809 - loss: 1.1835 - val_acc: 0.4761 - val_loss: 1.2066\n",
            "Epoch 202/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4821 - loss: 1.1853 - val_acc: 0.4818 - val_loss: 1.2025\n",
            "Epoch 203/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4826 - loss: 1.1843 - val_acc: 0.4771 - val_loss: 1.2046\n",
            "Epoch 204/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4795 - loss: 1.1872 - val_acc: 0.4732 - val_loss: 1.2071\n",
            "Epoch 205/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4803 - loss: 1.1860 - val_acc: 0.4780 - val_loss: 1.2044\n",
            "Epoch 206/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4783 - loss: 1.1880 - val_acc: 0.4830 - val_loss: 1.2076\n",
            "Epoch 207/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4792 - loss: 1.1867 - val_acc: 0.4772 - val_loss: 1.2108\n",
            "Epoch 208/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4842 - loss: 1.1833 - val_acc: 0.4754 - val_loss: 1.2035\n",
            "Epoch 209/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4767 - loss: 1.1876 - val_acc: 0.4797 - val_loss: 1.2044\n",
            "Epoch 210/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4773 - loss: 1.1894 - val_acc: 0.4783 - val_loss: 1.2024\n",
            "Epoch 211/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4787 - loss: 1.1910 - val_acc: 0.4793 - val_loss: 1.2045\n",
            "Epoch 212/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4818 - loss: 1.1846 - val_acc: 0.4713 - val_loss: 1.2056\n",
            "Epoch 213/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4831 - loss: 1.1825 - val_acc: 0.4814 - val_loss: 1.2046\n",
            "Epoch 214/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4813 - loss: 1.1845 - val_acc: 0.4786 - val_loss: 1.2053\n",
            "Epoch 215/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4796 - loss: 1.1865 - val_acc: 0.4804 - val_loss: 1.2075\n",
            "Epoch 216/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4816 - loss: 1.1850 - val_acc: 0.4737 - val_loss: 1.2053\n",
            "Epoch 217/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4808 - loss: 1.1865 - val_acc: 0.4785 - val_loss: 1.2046\n",
            "Epoch 218/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4803 - loss: 1.1844 - val_acc: 0.4721 - val_loss: 1.2051\n",
            "Epoch 219/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4799 - loss: 1.1817 - val_acc: 0.4756 - val_loss: 1.2082\n",
            "Epoch 220/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4793 - loss: 1.1849 - val_acc: 0.4796 - val_loss: 1.2043\n",
            "Epoch 221/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4771 - loss: 1.1860 - val_acc: 0.4723 - val_loss: 1.2041\n",
            "Epoch 222/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4783 - loss: 1.1864 - val_acc: 0.4779 - val_loss: 1.2023\n",
            "Epoch 223/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4800 - loss: 1.1866 - val_acc: 0.4724 - val_loss: 1.2069\n",
            "Epoch 224/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4798 - loss: 1.1839 - val_acc: 0.4755 - val_loss: 1.2054\n",
            "Epoch 225/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4852 - loss: 1.1797 - val_acc: 0.4749 - val_loss: 1.2051\n",
            "Epoch 226/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4837 - loss: 1.1807 - val_acc: 0.4788 - val_loss: 1.2034\n",
            "Epoch 227/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4823 - loss: 1.1830 - val_acc: 0.4771 - val_loss: 1.2060\n",
            "Epoch 228/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4808 - loss: 1.1851 - val_acc: 0.4801 - val_loss: 1.2059\n",
            "Epoch 229/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4823 - loss: 1.1883 - val_acc: 0.4730 - val_loss: 1.2080\n",
            "Epoch 230/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4797 - loss: 1.1879 - val_acc: 0.4776 - val_loss: 1.2068\n",
            "Epoch 231/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4852 - loss: 1.1809 - val_acc: 0.4798 - val_loss: 1.2038\n",
            "Epoch 232/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4820 - loss: 1.1854 - val_acc: 0.4773 - val_loss: 1.2078\n",
            "Epoch 233/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4785 - loss: 1.1921 - val_acc: 0.4789 - val_loss: 1.2016\n",
            "Epoch 234/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4802 - loss: 1.1854 - val_acc: 0.4801 - val_loss: 1.2041\n",
            "Epoch 235/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4823 - loss: 1.1810 - val_acc: 0.4736 - val_loss: 1.2063\n",
            "Epoch 236/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4771 - loss: 1.1877 - val_acc: 0.4746 - val_loss: 1.2064\n",
            "Epoch 237/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4811 - loss: 1.1812 - val_acc: 0.4690 - val_loss: 1.2081\n",
            "Epoch 238/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4805 - loss: 1.1851 - val_acc: 0.4778 - val_loss: 1.2046\n",
            "Epoch 239/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4805 - loss: 1.1861 - val_acc: 0.4773 - val_loss: 1.2084\n",
            "Epoch 240/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4787 - loss: 1.1871 - val_acc: 0.4766 - val_loss: 1.2052\n",
            "Epoch 241/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4771 - loss: 1.1873 - val_acc: 0.4718 - val_loss: 1.2071\n",
            "Epoch 242/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4766 - loss: 1.1868 - val_acc: 0.4787 - val_loss: 1.2073\n",
            "Epoch 243/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - acc: 0.4835 - loss: 1.1816 - val_acc: 0.4778 - val_loss: 1.2063\n",
            "Epoch 244/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4777 - loss: 1.1887 - val_acc: 0.4699 - val_loss: 1.2066\n",
            "Epoch 245/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4839 - loss: 1.1815 - val_acc: 0.4772 - val_loss: 1.2101\n",
            "Epoch 246/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - acc: 0.4810 - loss: 1.1825 - val_acc: 0.4731 - val_loss: 1.2068\n",
            "Epoch 247/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4829 - loss: 1.1826 - val_acc: 0.4793 - val_loss: 1.2043\n",
            "Epoch 248/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4819 - loss: 1.1828 - val_acc: 0.4733 - val_loss: 1.2087\n",
            "Epoch 249/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - acc: 0.4790 - loss: 1.1856 - val_acc: 0.4784 - val_loss: 1.2064\n",
            "Epoch 250/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4800 - loss: 1.1870 - val_acc: 0.4777 - val_loss: 1.2076\n",
            "Epoch 251/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4807 - loss: 1.1834 - val_acc: 0.4792 - val_loss: 1.2038\n",
            "Epoch 252/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4758 - loss: 1.1928 - val_acc: 0.4817 - val_loss: 1.2036\n",
            "Epoch 253/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4818 - loss: 1.1838 - val_acc: 0.4782 - val_loss: 1.2052\n",
            "Epoch 254/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - acc: 0.4822 - loss: 1.1807 - val_acc: 0.4812 - val_loss: 1.2069\n",
            "Epoch 255/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4869 - loss: 1.1806 - val_acc: 0.4790 - val_loss: 1.2070\n",
            "Epoch 256/256\n",
            "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - acc: 0.4843 - loss: 1.1807 - val_acc: 0.4782 - val_loss: 1.2085\n",
            "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 264ms/step\n"
          ]
        }
      ],
      "source": [
        "with_answer_verifier= 3\n",
        "without_answer_verifier= 2\n",
        "\n",
        "# with BM25, AVD, and DRD\n",
        "challenge_score_with_answer_verifier = answer_with_attention_score(train_challenge, dev_challenge,\n",
        "                                                                   with_answer_verifier)\n",
        "easy_score_with_answer_verifier = answer_with_attention_score(train_easy, dev_easy,\n",
        "                                                              with_answer_verifier)\n",
        "\n",
        "# with BM25, and DRD\n",
        "challenge_score_without_answer_verifier = answer_with_attention_score(train_challenge, dev_challenge,\n",
        "                                                                      without_answer_verifier)\n",
        "easy_score_without_answer_verifier = answer_with_attention_score(train_easy, dev_easy,\n",
        "                                                                 without_answer_verifier)"
      ]
    }
  ]
}