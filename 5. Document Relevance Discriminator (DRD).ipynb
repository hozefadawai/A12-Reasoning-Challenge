{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc-9FRcbJnPE"
      },
      "source": [
        "# Document Relevance Discriminator (DRD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLCjUuDUYHCO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading SQUAD Dataset"
      ],
      "metadata": {
        "id": "EXLCFxJf47-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtdQ4EbzWtQi",
        "outputId": "382ff1aa-1b08-4631-ee5c-bd2fb322a04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-20 06:04:02--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M   194MB/s    in 0.2s    \n",
            "\n",
            "2023-12-20 06:04:03 (194 MB/s) - ‘train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2023-12-20 06:04:03--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-20 06:04:03 (58.6 MB/s) - ‘dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# downoading SQUAD 2.0 dataset\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PilXO-zbYKAj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_squad(location):\n",
        "# Load the SQuAD JSON dataset into a Python dictionary\n",
        "    with open(location, 'r', encoding='utf-8') as file:\n",
        "        squad_data = json.load(file)\n",
        "\n",
        "    # Initialize lists to store data\n",
        "    questions = []\n",
        "    contexts = []\n",
        "    labels = []\n",
        "\n",
        "    # Process each example in the dataset\n",
        "    for example in squad_data[\"data\"]:\n",
        "        for paragraph in example[\"paragraphs\"]:\n",
        "            context = paragraph[\"context\"]\n",
        "            for qa in paragraph[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                is_impossible = qa.get(\"is_impossible\", False)\n",
        "\n",
        "                # Assign labels (0 for impossible, 1 for answerable)\n",
        "                label = 0 if is_impossible else 1\n",
        "\n",
        "                questions.append(question)\n",
        "                contexts.append(context)\n",
        "                labels.append(label)\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame({\"question\": questions, \"context\": contexts, \"label\": labels})\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoK3lMNPXpFW"
      },
      "outputs": [],
      "source": [
        "squad_train = load_squad(\"/content/train-v2.0.json\" )\n",
        "squad_dev = load_squad(\"/content/dev-v2.0.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjgPfO4OOb87"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_special_characters(input_string):\n",
        "    # Use a regular expression to replace all non-alphanumeric characters with an empty string\n",
        "    clean_string=[]\n",
        "    for text in input_string:\n",
        "        clean_string.append(re.sub(r'[^a-zA-Z0-9\\s]', '', text))\n",
        "    return clean_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfXXgbsYOiZ_"
      },
      "outputs": [],
      "source": [
        "squad_train['context'] = remove_special_characters(squad_train['context'])\n",
        "squad_dev['context'] = remove_special_characters(squad_dev['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "a6cTfyeOPVCS",
        "outputId": "d22cc65f-bae2-4e12-e096-3a2199c430c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-60c955d1-c76c-4fee-bd4d-9b0200586a8b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What areas did Beyonce compete in when she was growing up?</td>\n",
              "      <td>Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>When did Beyonce leave Destiny's Child and become a solo singer?</td>\n",
              "      <td>Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60c955d1-c76c-4fee-bd4d-9b0200586a8b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60c955d1-c76c-4fee-bd4d-9b0200586a8b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60c955d1-c76c-4fee-bd4d-9b0200586a8b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b373f352-2c23-4fcc-8e5a-950dda0fc1bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b373f352-2c23-4fcc-8e5a-950dda0fc1bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b373f352-2c23-4fcc-8e5a-950dda0fc1bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                           question  \\\n",
              "0                          When did Beyonce start becoming popular?   \n",
              "1        What areas did Beyonce compete in when she was growing up?   \n",
              "2  When did Beyonce leave Destiny's Child and become a solo singer?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       context  \\\n",
              "0  Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy   \n",
              "1  Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy   \n",
              "2  Beyonc Giselle KnowlesCarter bijnse beeYONsay born September 4 1981 is an American singer songwriter record producer and actress Born and raised in Houston Texas she performed in various singing and dancing competitions as a child and rose to fame in the late 1990s as lead singer of RB girlgroup Destinys Child Managed by her father Mathew Knowles the group became one of the worlds bestselling girl groups of all time Their hiatus saw the release of Beyoncs debut album Dangerously in Love 2003 which established her as a solo artist worldwide earned five Grammy Awards and featured the Billboard Hot 100 numberone singles Crazy in Love and Baby Boy   \n",
              "\n",
              "   label  \n",
              "0      1  \n",
              "1      1  \n",
              "2      1  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "squad_train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etMfyY-MPXUb"
      },
      "source": [
        "###training model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbjtlD50Pi92",
        "outputId": "ae4cea09-054a-46a4-bb0c-e8add0f8b0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iw0ND9QRPi92"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "88d39b7e2e65446e8851f52650db9575",
            "d027ad300aa44014bb8a6067bb815400",
            "aac3e8c5eaf64c76954bd1887d2493a7",
            "fcc76bfb9dc14ae7abd5f7009147fc8d",
            "bd9b3b39ee1a4f91b1b9404e81bb5c23",
            "d29292d4f838415f991140530c0bd670",
            "99800fa1ff0249caa4be55efa9bdda77",
            "bea8735c8d974681b75d4509ed983845",
            "125209cee77843be83c4b66df9d13855",
            "82ffc3226feb42088c36b86bc54cde01",
            "d6339f0e3ea94eb3943ddbf4bf2418e0",
            "a8bcbda4fca54e0798fbce2f26754e3e",
            "54660cb7a771498d8aa3e4e6cd01e350",
            "9961ad0bf90a479394b414b9e9f24763",
            "842ae0c783854d2a82cce2b7ade674fc",
            "745f2d86eda34c9dac2f0ddbd15a0a4e",
            "4374bec1e46a43f3902e34d3522bc73d",
            "b6be40ec134f48889c1ac553f57fc23f",
            "8e85ea4688dd4a18b8c0c8e021a6e465",
            "ac143342dfcd4c05992c85538e411774",
            "6625eab9ab7a4c2aaf48624941ede626",
            "0a109247aa5e433095a72c271d0a862b",
            "65a0f5c9a1c44b5b964743eaba6e75d6",
            "43704ea5998c47f3a27261f697882c6b",
            "285b57a995e14707b1966b2ab641e4f5",
            "a8404b8b03b74883bf95dabae0c533a8",
            "165dab1957ef492db5a723d89aa2dbb2",
            "28c41aa647704468bbb5ce163de2f532",
            "1f327c1b51594583ae13a7fefee9e07e",
            "0b27ed1de8334584b174e0df68fec356",
            "cb1361c2e0d14002a99361a43e8fe2f1",
            "573b369103e54d7aae42266f4a2afca9",
            "e91d1c156aec4a8c8f6ae0e281502b64",
            "0d9ba2b9b02a47d78a903cc4a2019167",
            "11f9e523ed4749a48725424fd9ce4def",
            "e4ea89a9602d41e8a09767f00f8be5d6",
            "8134509bdee442b68074a78b60a44189",
            "f42a2d3c43734b11a9f098386b548bf9",
            "c2bcc7d4ac1b4d56b7e772cc6416a679",
            "3f72c46522de4732ba95e6230fb963b4",
            "1f5cb970860e42079f12d87ad18dc044",
            "4a629305f2ab440c933726b9d5a53b7c",
            "c7e62756891d441ba3ef8f378c0ad6d6",
            "051cfb0e33fd4b40a39bc6d7db11d6fc"
          ]
        },
        "id": "qQUh8gn1knjg",
        "outputId": "819adb25-5d79-419f-96ee-138e2f9ef858"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88d39b7e2e65446e8851f52650db9575",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8bcbda4fca54e0798fbce2f26754e3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a0f5c9a1c44b5b964743eaba6e75d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d9ba2b9b02a47d78a903cc4a2019167",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"google/flan-t5-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTV8jJL1YOAf",
        "outputId": "78b42df6-437f-4c56-98b9-0989cd899c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90th percentile: 182.0\n",
            "91th percentile: 187.0\n",
            "92th percentile: 192.0\n",
            "93th percentile: 197.0\n",
            "94th percentile: 203.0\n",
            "95th percentile: 212.0\n",
            "96th percentile: 221.0\n",
            "97th percentile: 233.0\n",
            "98th percentile: 252.0\n",
            "99th percentile: 285.0\n",
            "100th percentile: 650.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate percentiles\n",
        "percentiles = np.percentile([len(i.split())for i in squad_train['context']] , range(90, 101))\n",
        "\n",
        "# Print the percentiles\n",
        "for p, percentile_value in zip(range(90, 101), percentiles):\n",
        "    print(f\"{p}th percentile: {percentile_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXMwxDHdYj_K",
        "outputId": "08ce9a40-4dec-453e-d2ec-603d54f44866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90th percentile: 14.0\n",
            "91th percentile: 15.0\n",
            "92th percentile: 15.0\n",
            "93th percentile: 15.0\n",
            "94th percentile: 16.0\n",
            "95th percentile: 16.0\n",
            "96th percentile: 17.0\n",
            "97th percentile: 17.0\n",
            "98th percentile: 18.0\n",
            "99th percentile: 20.0\n",
            "100th percentile: 40.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate percentiles\n",
        "percentiles = np.percentile([len(i.split())for i in squad_train['question']] , range(90, 101))\n",
        "\n",
        "# Print the percentiles\n",
        "for p, percentile_value in zip(range(90, 101), percentiles):\n",
        "    print(f\"{p}th percentile: {percentile_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRucJlDSQH2K"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def tokenizing_df(dataset):\n",
        "\n",
        "    max_seq_length = 512\n",
        "    dataset_len =len(dataset)\n",
        "\n",
        "    input_ids = np.zeros((dataset_len, max_seq_length))\n",
        "    attention_mask= np.zeros((dataset_len, max_seq_length))\n",
        "\n",
        "    target_input_ids= np.zeros((dataset_len, 2))\n",
        "    target_attention_mask= np.zeros((dataset_len, 2))\n",
        "\n",
        "    for i, row in tqdm(dataset.iterrows()):\n",
        "\n",
        "\n",
        "        # now truncating tokens to max length\n",
        "\n",
        "        # adding [CLS] at the begining and [SEP] at the end of the sentence\n",
        "        pair = row['question'] + '</s>' + row['context']\n",
        "        # converting tokens to unique IDs\n",
        "        tokens = tokenizer.encode(pair)\n",
        "        # adding zeros in the last if the size of the text is less than max length\n",
        "        input_ids[i, :]= np.array(tokens + [0]*(max_seq_length-len(tokens)))[None,:512]\n",
        "        # masking vector\n",
        "        attention_mask[i, :]= np.array([1]*len(tokens) + [0]*(max_seq_length-len(tokens)))[None,:512]\n",
        "\n",
        "\n",
        "        if row['label'] == 0:\n",
        "\n",
        "          tokens = tokenizer.encode('A')\n",
        "\n",
        "          target_input_ids[i, :] = np.array(tokens)[None,:]\n",
        "\n",
        "          target_attention_mask[i, :] = np.array([1]*len(tokens))[None, :]\n",
        "\n",
        "        else:\n",
        "\n",
        "          tokens = tokenizer.encode('B')\n",
        "\n",
        "\n",
        "          target_input_ids[i, :] = np.array(tokens)[None,:]\n",
        "\n",
        "          target_attention_mask[i, :] = np.array([1]*len(tokens))[None, :]\n",
        "\n",
        "\n",
        "\n",
        "    tokenized_data= np.array([input_ids, attention_mask],  dtype= 'int16')\n",
        "    target_data =np.array([target_input_ids, target_attention_mask], dtype= 'int16')\n",
        "\n",
        "\n",
        "    return tokenized_data, target_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC07zuWRI4qJ",
        "outputId": "b4369bca-72a9-47f1-f268-ff8f1e2560ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "130319it [02:38, 824.68it/s]\n",
            "11873it [00:14, 827.11it/s]\n"
          ]
        }
      ],
      "source": [
        "squad_x_train, squad_y_train = tokenizing_df(squad_train)\n",
        "squad_x_dev, squad_y_dev = tokenizing_df(squad_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJSxu6SvPi95"
      },
      "outputs": [],
      "source": [
        "pickle.dump((squad_x_train, squad_y_train, squad_x_dev, squad_y_dev),\n",
        "            open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/squad_tokenized_t5_xl_512.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMBogNcHPi96"
      },
      "outputs": [],
      "source": [
        "squad_x_train, squad_y_train, squad_x_dev, squad_y_dev= \\\n",
        "pickle.load(open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/squad_tokenized_t5_xl_512.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXLtMFYuPi97"
      },
      "outputs": [],
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "531ea0fa57504147aa28f78e085c3f86",
            "c7c57f45adf54f69b7b9788b86e7e067",
            "4ea2893f5a464babba0ce9f795278ba1",
            "626c2297949e4fc1b4878ec44db0448c",
            "e44cecb89a6e415f8b3e73b38bb85b74",
            "99e1031913824e28b7217e8787590368",
            "1b5383488413425d8ae2728b9e79c9d9",
            "a64d7ee3176743d68e60eddea93854da",
            "b791ac1c783d43979e4ccd8e288ed01d",
            "0cd53451d44c47e4a62315152135bad1",
            "b8a5917ab02f49e49915a8904cb781ea",
            "3343157e59b34e7fa33f35d092b436d2",
            "5974fa5ac10843cea224b937607d0ed3",
            "3a62409a45234e7c86c15a5b80d30812",
            "c0bcffd2484b4bb491889621d756de3b",
            "c42be38f44194b7aaebc187858a8b90b",
            "08e901918792461daedaad3fc1d81ac5",
            "2ad91e439e4c417a9a4c4849a0472592",
            "feee59cb2a6d4c6d82cde182da9cee59",
            "b23d71cd5f8a4aa9b18e7e15fbcbc7ee",
            "11308730769a44c8a651bd83efca303c",
            "89dd52c5c0b34a5881cc332008596254"
          ]
        },
        "id": "_WFrQRT6Pi97",
        "outputId": "5d0ff0cb-a6a4-4452-924b-23e09dd46b38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531ea0fa57504147aa28f78e085c3f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3343157e59b34e7fa33f35d092b436d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFT5ForConditionalGeneration\n",
        "strategy = tf.distribute.TPUStrategy(resolver)\n",
        "\n",
        "optimizer = tf.keras.optimizers.AdamW(3e-5, clipnorm= 1.0, epsilon= 1e-6)\n",
        "#loss= tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = TFT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "    model.compile(optimizer= optimizer,\n",
        "                  metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYzmzn5xPi98"
      },
      "outputs": [],
      "source": [
        "# function to save new best model with higher Validation accuracy\n",
        "filepath=\"/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/DRD model on Squad/weights-{epoch:02d}-{val_accuracy:.4f}.tf\"\n",
        "checkpoint=  ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             verbose=1,\n",
        "                             mode='max',\n",
        "                             save_weights_only=False,\n",
        "                             options= tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\"))\n",
        "\n",
        "# function to reduce learning rate if validation accuracy stop moving or decreasing\n",
        "rlr = ReduceLROnPlateau(monitor=\"val_accuracy\", factor= 0.1, min_lr= 0.000001,\n",
        "           patience=1, verbose=1, mode = 'max')\n",
        "\n",
        "# it will monitor validation accuracy if it has stop improving or giving constant accuracy at each epoch\n",
        "# earlystop = EarlyStopping(monitor=\"val_accuracy\", patience=2, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skvk1dt9C8FQ"
      },
      "outputs": [],
      "source": [
        "train = {'input_ids':squad_x_train[0], 'attention_mask': squad_x_train[1],\n",
        "               'labels':squad_y_train[0], 'decoder_attention_mask':squad_y_train[1]}\n",
        "\n",
        "dev = {'input_ids':squad_x_dev[0], 'attention_mask': squad_x_dev[1],\n",
        "               'labels':squad_y_dev[0], 'decoder_attention_mask':squad_y_dev[1]}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs= 3\n",
        "batch = 32\n",
        "\n",
        "model.fit(x= train,\n",
        "          validation_data= dev,\n",
        "          verbose= 1,\n",
        "          epochs= epochs,\n",
        "          batch_size= batch,\n",
        "          shuffle =True,)\n",
        "        #   callbacks=[checkpoint, rlr])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-15T04:03:38.757073Z",
          "iopub.execute_input": "2023-12-15T04:03:38.757352Z",
          "iopub.status.idle": "2023-12-15T06:02:04.757667Z",
          "shell.execute_reply.started": "2023-12-15T04:03:38.757325Z",
          "shell.execute_reply": "2023-12-15T06:02:04.756653Z"
        },
        "trusted": true,
        "outputId": "07c653ab-334e-417b-b1f2-a290d7d595c1",
        "id": "yHwkG04m4hjC"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:03:39.759688: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.777042: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.794161: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.811362: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.828337: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.845319: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:03:39.862792: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:05:57.248599: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AdamW/AssignAddVariableOp.\n2023-12-15 04:06:12.643280: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.646500: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.646652: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.646747: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.646910: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.647016: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.647119: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.647249: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.647383: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.647714: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:06:12.648061: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.824397: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.830989: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.832337: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.832611: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.832698: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.832811: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.832914: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:08.833597: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   1/4073 [..............................] - ETA: 372:53:39 - loss: 5.8449 - accuracy: 0.1094",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:09:09.590150: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.590341: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.590547: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.590656: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.590761: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.590949: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:09.591360: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   2/4073 [..............................] - ETA: 35:24 - loss: 5.7929 - accuracy: 0.1328    ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:09:10.108220: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:10.108459: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:10.108573: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:10.108703: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n2023-12-15 04:09:10.108864: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   3/4073 [..............................] - ETA: 35:18 - loss: 5.5502 - accuracy: 0.1615",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:09:10.628942: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  19/4073 [..............................] - ETA: 35:37 - loss: 3.5736 - accuracy: 0.4062",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:09:19.077711: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "  49/4073 [..............................] - ETA: 35:08 - loss: 1.8958 - accuracy: 0.5928",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:09:34.734061: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2649/4073 [==================>...........] - ETA: 12:25 - loss: 0.2007 - accuracy: 0.9200",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:32:15.019680: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "4073/4073 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9321",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 04:48:03.682705: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-12-15 04:48:35.070019: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "4073/4073 [==============================] - 2753s 595ms/step - loss: 0.1711 - accuracy: 0.9321 - val_loss: nan - val_accuracy: 0.9499\nEpoch 2/3\n4073/4073 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9664",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2023-12-15 05:25:15.782516: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "4073/4073 [==============================] - 2177s 534ms/step - loss: 0.0882 - accuracy: 0.9664 - val_loss: nan - val_accuracy: 0.9548\nEpoch 3/3\n4073/4073 [==============================] - 2175s 534ms/step - loss: 0.0615 - accuracy: 0.9773 - val_loss: nan - val_accuracy: 0.9553\n",
          "output_type": "stream"
        },
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.History at 0x7d74bc3e0d00>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('squad_saved_weights_t5_large.h5',\n",
        "           options=  tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\"))"
      ],
      "metadata": {
        "id": "ArX1o6jV2ocg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "GA-HnwOwhbKv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "7cde1af51762463283aa0231885928c0",
            "3da497fbc000460c936b380f92249225",
            "fa4fbd6be6c74f4bae715fbc6f47528c",
            "af33ba63de4844b2b8a317193d276115",
            "b19b00fc04d140068f606f5cd1903e58",
            "2bb78bf50036403cbe09daa36f85f23a",
            "cf08e216ede8425587e818f6519d08ad",
            "1d4f2c43f20e4e189689577620d7d519",
            "4cfa11db0da241aabb633996440b7b16",
            "4168ce20cbce41ffbb3c7110639d047c",
            "f7eb50d3bd7044f984153ad4976c5214",
            "120227c523f947368b0601109542253b",
            "55c40994cc6542e685baef8266031fdb",
            "89482b39cdf04ab18f0e7850d9e7761f",
            "f317f25bb4e74077a1d5a465bd3c8d34",
            "2ea058130f9c46239644acde5b0818af",
            "69bcfc9696ea456380ec2d0ee051dcad",
            "d285edf424b7474c8b126ae071c932e2",
            "867c4d3633e3445393cfc510324aa3c4",
            "b181b528ee2940f6914ba690a936b799",
            "308b638539b641088be146f3c9e0cfc8",
            "73cac04b23ef430ebdaf6c09247d85df"
          ]
        },
        "id": "JMnFhi2QoSrc",
        "outputId": "0c65227b-df5a-4ab3-d7b0-39a5c3566807"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cde1af51762463283aa0231885928c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "120227c523f947368b0601109542253b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFT5ForConditionalGeneration\n",
        "optimizer = tf.keras.optimizers.AdamW(3e-5, clipnorm= 1.0, epsilon= 1e-6)\n",
        "#loss= tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "model = TFT5ForConditionalGeneration.from_pretrained('google/flan-t5-large')\n",
        "model.compile(optimizer= optimizer,\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhQELpRHXkTQ"
      },
      "outputs": [],
      "source": [
        "path= '/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/squad_saved_weights_t5_large.h5'\n",
        "model.load_weights(path)\n",
        "# ,  options = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eNQig3t0cyL",
        "outputId": "c9e3f330-bd78-47d3-a6a1-35324ff745e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9107218057778153\n"
          ]
        }
      ],
      "source": [
        "# Accuracy score on dev dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "squad_predicted= []\n",
        "for i in tqdm(range(0, len(squad_x_dev[0]), 50)):\n",
        "    squad_predicted.append(model.generate(squad_x_dev[0][i:i+50], output_scores=True, return_dict_in_generate=True))\n",
        "\n",
        "\n",
        "squad_predicted_labels= [0 if tokenizer.decode(sequence[1]) == 'A' else 1 for i in squad_predicted for sequence in i['sequences']]\n",
        "\n",
        "# Calculate the accuracy score\n",
        "accuracy = accuracy_score(squad_dev['label'], squad_predicted_labels)\n",
        "\n",
        "# Print the accuracy score\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### generating DRD scores"
      ],
      "metadata": {
        "id": "8mTciiVeduw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def avd_score(model, tokenizer, data):\n",
        "  '''\n",
        "  function to get AVD scores from downstream model trained on RACE data set\n",
        "  '''\n",
        "    # device = xm.xla_device()\n",
        "    device = torch.device('cuda')\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    question= data['only_questions']\n",
        "    answer= data['only_answers']\n",
        "    context = data['context']\n",
        "    scores = []\n",
        "\n",
        "    # it will iterate through each question\n",
        "    for i, que in enumerate(tqdm(question)):\n",
        "        list_of_scores= []\n",
        "        # it will iterate through each answer of that particular question\n",
        "        # each question has four option so it will iterate four times\n",
        "        for j, ans in enumerate(answer[i]):\n",
        "            # it will get contexts of particular question with particular option\n",
        "            # it will get 50 contexts\n",
        "            context_len = len(context[i][j])\n",
        "\n",
        "            # we will pair question and answer and multiply with 50 times to match context length\n",
        "            pair= [que + '</s>' + ans] * context_len\n",
        "\n",
        "            # now we have 50 pairs of ques and ans and 50 contexts\n",
        "            # now we will tokenize them\n",
        "            tokens= tokenizer(pair, context[i][j], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "\n",
        "            input_ids= torch.unsqueeze(tokens['input_ids'], dim=0).to(device)\n",
        "            attention_mask= torch.unsqueeze(tokens['attention_mask'], dim=0).to(device)\n",
        "\n",
        "            # this below code will get softmax scores of each question, answer and context pair which is 50\n",
        "            with torch.no_grad():\n",
        "\n",
        "              logits= model(input_ids, attention_mask).logits\n",
        "            logits.detach()\n",
        "            softmax = torch.nn.functional.softmax(logits[0], dim= -1)\n",
        "            list_of_scores.append(softmax.tolist())\n",
        "\n",
        "        # now we will append softmax scores to the list of all 50 scores\n",
        "        # each question have 4 options and each option has 50 context scores\n",
        "        scores.append(list_of_scores)\n",
        "\n",
        "    return scores"
      ],
      "metadata": {
        "id": "3ENkLo19ebIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGCR9krBH6pr"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "def drd_score(data):\n",
        "  '''\n",
        "  function to get DRD scores from downstream model trained on SQUAD dataset\n",
        "  '''\n",
        "    question= data['only_questions']\n",
        "    answer= data['only_answers']\n",
        "    context = data['context']\n",
        "\n",
        "    scores = []\n",
        "    # it will iterate through each question\n",
        "    for i, que in enumerate(tqdm(question)):\n",
        "        list_of_scores= []\n",
        "        # it will iterate through each answer of that particular question\n",
        "        # each question has four option so it will iterate four times\n",
        "        for j, ans in enumerate(answer[i]):\n",
        "            # it will get contexts of particular question with particular option\n",
        "            # it will get 50 contexts\n",
        "            context_len = len(context[i][j])\n",
        "            # we will multiply question 50 times to match with context length\n",
        "            pair= [que] * context_len\n",
        "\n",
        "            # now we have 50 pairs of question and 50 contexts\n",
        "            # now we will tokenize them\n",
        "            tokens = tokenizer(pair, context[i][j], padding= True, truncation=True, return_tensors=\"tf\")\n",
        "            # model will generate probabilty scores of each 50 contexts\n",
        "\n",
        "            predict = model.generate(tokens['input_ids'], output_scores=True, return_dict_in_generate=True)\n",
        "\n",
        "            softmax = tf.nn.softmax(predict['scores'][0], axis= -1)\n",
        "\n",
        "            max_values = np.max(softmax, axis = -1)\n",
        "\n",
        "            # softmax = tf.nn.softmax(max_values, axis= -1)\n",
        "            # softmax = [tf.nn.softmax(i).tolist() for i in max_values]\n",
        "\n",
        "\n",
        "            list_of_scores.append(max_values.tolist())\n",
        "\n",
        "        # now we will append softmax scores to the list of all 50 scores\n",
        "        # each question have 4 options and each option has 50 context scores\n",
        "        scores.append(list_of_scores)\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fP1RywakY2cS"
      },
      "outputs": [],
      "source": [
        "def joining_scores(data, new_scores):\n",
        "  '''\n",
        "  This fuction will join DRD scores with existing BM25 scores\n",
        "  '''\n",
        "    old_scores = data['score']\n",
        "    scores =[]\n",
        "    for idx_1, score_1 in enumerate(old_scores):\n",
        "        list_of_scores= []\n",
        "        for idx_2, score_2 in enumerate(score_1):\n",
        "\n",
        "            list_of_scores.append([[score_3] + [new_scores[idx_1][idx_2][idx_3]] for idx_3, score_3 in enumerate(score_2)])\n",
        "        scores.append(list_of_scores)\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQvmZbPRm0Vt",
        "outputId": "38ff9679-623a-4fd3-b26d-e2a6c8373261"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1119/1119 [1:00:08<00:00,  3.23s/it]\n",
            "100%|██████████| 299/299 [16:10<00:00,  3.25s/it]\n",
            "100%|██████████| 1172/1172 [1:04:03<00:00,  3.28s/it]\n"
          ]
        }
      ],
      "source": [
        "train_challenge['score']= joining_scores(train_challenge, drd_score(train_challenge))\n",
        "dev_challenge['score']= joining_scores(dev_challenge, drd_score(dev_challenge))\n",
        "test_challenge['score']= joining_scores(test_challenge, drd_score(test_challenge))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-4AZhs9rU4v"
      },
      "outputs": [],
      "source": [
        "pickle.dump((train_challenge, dev_challenge, test_challenge),\n",
        "            open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/arc_datasets_scores_challenge.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbGqWgJ-E6SD",
        "outputId": "61b88e7d-e630-4006-db42-9ac52467d8a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2251/2251 [1:58:42<00:00,  3.16s/it]\n",
            "100%|██████████| 570/570 [29:21<00:00,  3.09s/it]\n",
            "100%|██████████| 2376/2376 [2:03:09<00:00,  3.11s/it]\n"
          ]
        }
      ],
      "source": [
        "train_easy['score']= joining_scores(train_easy, drd_score(train_easy))\n",
        "dev_easy['score']= joining_scores(dev_easy, drd_score(dev_easy))\n",
        "test_easy['score']= joining_scores(test_easy, drd_score(test_easy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ7a-6pvNuZ8"
      },
      "outputs": [],
      "source": [
        "pickle.dump((train_easy, dev_easy, test_easy),\n",
        "            open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/arc_datasets_scores_easy.pkl','wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0ghqvkYrU43"
      },
      "outputs": [],
      "source": [
        "train_challenge, dev_challenge, test_challenge= \\\n",
        "pickle.load(open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/arc_datasets_scores_challenge.pkl', 'rb'))\n",
        "\n",
        "train_easy, dev_easy, test_easy= \\\n",
        "pickle.load(open('/content/drive/MyDrive/my assignments/33. A12 Reasoning Challenge- Self case study 2/arc_datasets_scores_easy.pkl', 'rb'))"
      ]
    }
  ]
}